### Sprint-5 ‚Äî Rapport QA (26 octobre 2025)

üìå Version : v1.1
üßæ Auteur QA : ATLAS (Manager/QA Architect)
üóìÔ∏è Date : 2025-10-26

---

## R√©sum√© ex√©cutif

Sprint-5 livr√© √† ~80%.

- Fusion importante : `feat/backtests-eval-pages` ‚Üí `main` (merge `sprint-5 2/5`).
- Nouveaux artefacts ajout√©s : pages `/backtests`, `/evaluation` et agents `backtest_agent`, `evaluation_agent`.
- Actions requises : validation UX compl√®te (MCP + web_eval_agent), g√©n√©ration de donn√©es par les agents, et ajout d'artifacts/logs.

---

## Commits examin√©s

| Commit | Objet | Commentaire |
|---|---|---|
| `3e0e235` | sprint-5 2/5: merge feat/backtests-eval-pages into main | Merge r√©alis√© ‚Äî √† valider fonctionnellement (voir tests) |
| `ffa805a` | sprint-5 1/5 docs: update commit message policy to include sprint/progress | Doc mise √† jour pour exigence sprint/progress |
| `8b27e9d` | feat(agents/pages): add backtest & evaluation agents and pages; docs + tests | Ajout des agents/pages; n√©cessite g√©n√©ration de donn√©es |
| `09e3ee6` | Sprint-5: QA report - 3/5 pages delivered, smoke tests 12/12 passing | QA report initial pr√©sent dans docs |

---

## Validation requise (actions QA)

1. G√©n√©rer les donn√©es d'entr√©e pour les agents :

```bash
make equity-forecast && make forecast-aggregate
make macro-forecast && make update-monitor
```

2. Ex√©cuter les agents Backtest & Evaluation (si cibles Make pr√©sentes) :

```bash
make backtest || PYTHONPATH=src python -m src.agents.backtest_agent --horizon 1m --top-n 5
make evaluate || PYTHONPATH=src python -m src.agents.evaluation_agent --horizon 1m
```

3. V√©rifier la pr√©sence des sorties dat√©es :

- `data/backtest/dt=YYYYMMDD/*` (details.parquet, summary.json)
- `data/evaluation/dt=YYYYMMDD/*` (metrics.json, details.parquet)

4. D√©marrer l'UI et ex√©cuter les tests automatis√©s :

```bash
make dash-restart-bg
make dash-smoke        # v√©rifie HTTP 200 sur routes connues
make dash-mcp-test     # ex√©cute le script MCP (UX automatis√©)
pytest -q              # ex√©cute les tests unitaires
```

5. Lancer `web_eval_agent` (facultatif / visible) pour naviguer et capturer screenshots :

```json
{ "url": "http://localhost:8050", "task": "Navigate through all pages including Backtests and Evaluation; verify data tables, metrics, charts and absence of console errors.", "headless_browser": false }
```

6. Collecter et joindre les sorties :

- `logs/mcp_ui_test.log` (stdout/stderr du script MCP)
- `artifacts/web_eval/report.json` et `artifacts/web_eval/screenshots/*`
- Exemplaires de `data/backtest/dt=*/details.parquet` et `data/evaluation/dt=*/metrics.json` si possible

---

## R√©sultats attendus / Crit√®res de succ√®s

- Toutes les routes (incl. `/backtests`, `/evaluation`) r√©pondent HTTP 200.
- Les DataTables et graphiques se chargent sans erreurs de callback.
- Fichiers dat√©s produits par les agents (dt=YYYYMMDD) pr√©sents.
- Aucun stacktrace dans `logs/` et pas de secrets expos√©s.
- MCP / web_eval_agent produit un rapport et des screenshots (artifacts/web_eval/).

---

## Probl√®mes connus / Points de vigilance

- V√©rifier idempotence des agents : n‚Äô√©crivent que dans dt=today.
- Assurer que les agents loggent d√©but/fin et warnings.
- Pages Dash doivent g√©rer √©tat vide FR si pas de donn√©es.
- S‚Äôassurer d‚Äô√©viter la duplication de logique avec les agents existants (ex. forecast aggregator).

---

## Recommandations & Next steps

1. Ex√©cuter la s√©quence de validation ci‚Äëdessus et joindre les logs/screenshots √† ce rapport.
2. Si des erreurs MCP apparaissent, open a bug PR with failing artefacts (screenshots + console errors).
3. Ajouter `data/backtest/` et `data/evaluation/` aux patterns de `.gitignore` si des fichiers temporaires locaux apparaissent par erreur.
4. Apr√®s validation, marquer Sprint-5 comme `4/5` dans `docs/PROGRESS.md` et appliquer le tag Git `sprint-5-complete` si souhait√©.

---

_Fichier g√©n√©r√© automatiquement par l‚Äôoutil de support dev ‚Äî compl√©ter avec les artefacts et logs une fois les tests ex√©cut√©s._
