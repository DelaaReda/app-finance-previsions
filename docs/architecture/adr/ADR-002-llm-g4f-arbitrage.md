# ADR-002 â€” LLM via g4f (GPT4Free) avec Arbitrage Multi-Agents

**Date**: 2025-10-29
**Statut**: âœ… AcceptÃ© (ImplÃ©mentÃ© Sprint Sonnet-2)
**DÃ©cideurs**: Reda + Ã‰quipe Dev
**RÃ©vision**: â€”

---

## Contexte

L'application gÃ©nÃ¨re **forecasts multi-sources** (momentum, macro, sentiment). ProblÃ¨me: **synthÃ©tiser** ces signaux pour investisseur non-expert (Reda).

**Besoins**:
1. RÃ©sumer 50+ forecasts en **3-5 recommandations claires** (FR)
2. Expliquer **pourquoi** (drivers technique/macro/sentiment)
3. Identifier **tensions** (ex: technique bullish mais macro bearish)
4. CoÃ»t **zÃ©ro** (budget limitÃ©)

**Options LLM**:
- **OpenAI GPT-4**: $0.03/1k tokens â†’ ~$50/mois (1500 calls/jour) âŒ CoÃ»t
- **Claude Sonnet**: $0.015/1k tokens â†’ ~$25/mois âŒ CoÃ»t
- **Ollama local**: Gratuit mais GPU RTX 3090 requis (~$1500) âŒ Hardware
- **g4f (GPT4Free)**: Gratuit, multi-models, pas de GPU âœ…

**Questions**:
1. g4f assez **robuste** pour production?
2. Quel **pattern** LLM (single prompt vs multi-agents)?
3. Comment garantir **explicabilitÃ©**?

---

## DÃ©cision

### 1. Provider: g4f (GPT4Free)
Utiliser **g4f** comme provider LLM principal.

**Justifications**:
- **CoÃ»t zÃ©ro**: Proxies gratuits vers models (DeepSeek R1, Qwen, GLM, Llama)
- **Multi-models**: 50+ models disponibles â†’ fallback si 1 down
- **Anonyme**: Pas de tracking, pas de clÃ©s API
- **CommunautÃ© active**: Repo GitHub 60k+ stars, updates rÃ©guliÃ¨res

**Mitigations instabilitÃ©**:
- **Retry automatique**: 2 retries avec backoff (2s, 4s)
- **Model fallback**: DeepSeek R1 â†’ Qwen 2.5 â†’ GLM-4
- **Timeout**: 30s max par requÃªte
- **Monitoring**: Logs success/failure â†’ alert si taux Ã©chec > 30%

### 2. Pattern: Multi-Agents â†’ Arbitre
Adopter **pattern ensemble** au lieu de prompt monolithique:

```
Agent Technique â†’ \
Agent Macro     â†’  â†’ Arbitre LLM â†’ SynthÃ¨se JSON (Pydantic validÃ©)
Agent Sentiment â†’ /
Agent QualitÃ©   â†’ /
```

**Justifications**:
- **ExplicabilitÃ©**: Chaque agent identifiÃ© dans `contributors` (source, rationale)
- **Robustesse**: Si 1 agent Ã©choue, arbitre peut compenser avec 3 autres
- **TestabilitÃ©**: Chaque agent testable unitairement (mock LLM)
- **Ã‰volutivitÃ©**: Ajouter agents (ex: Agent Sectoriel) sans changer arbitre

**Agents**:
1. **Technique**: Analyse Top-50 forecasts (momentum, scores)
2. **Macro**: Analyse rÃ©gime (expansion/contraction, risque)
3. **Sentiment**: AgrÃ¨ge news 7j par ticker
4. **QualitÃ©**: PÃ©nalise donnÃ©es pÃ©rimÃ©es (freshness > 48h)

**Arbitre**:
- **RÃ´le**: RÃ©concilier 4 agents â†’ synthÃ¨se consensuelle
- **Prompt**: "Tu es comitÃ© investissement, rÃ©concilie ces 4 analyses..."
- **Output**: JSON conformant schema `LLMEnsembleSummary` (Pydantic)

### 3. Schema: Pydantic Strict
Forcer **validation Pydantic** sur output LLM.

**Schema**:
```python
class LLMEnsembleSummary(BaseModel):
    regime: Literal["expansion_modÃ©rÃ©e", "dÃ©sinflation", "contraction", "incertain"]
    risk_level: Literal["low", "medium", "high"]
    outlook_days_7: Literal["positive", "neutral", "negative"]
    outlook_days_30: Literal["positive", "neutral", "negative"]
    key_drivers: List[str] = Field(min_items=3, max_items=5)
    contributors: List[Contributor]  # source, model, horizon, symbol, score, prediction, rationale
    limits: List[str]  # Ex: "DonnÃ©es macro H-48", "Faible couverture utilities"
```

**Justifications**:
- **Type safety**: Python runtime valide types (pas de "regime": 123)
- **Contraintes**: `min_items=3` garantit â‰¥ 3 key_drivers
- **SÃ©rialisation**: `.model_dump_json()` gÃ©nÃ¨re JSON propre
- **Documentation**: Schema = contrat API (autogen docs OpenAPI possible)

### 4. Orchestration: Horaire + Manuel
**Horaire**:
- **Scheduler**: APScheduler (top of every hour)
- **Make target**: `llm-summary-run`
- **Output**: `data/llm_summary/dt=YYYYMMDDHH/summary.json`

**Manuel**:
- **UI**: Bouton "Relancer maintenant" sur `/llm_summary`
- **Callback**: `run_make("llm-summary-run")` + affichage logs
- **Lock**: Anti collision (1 run Ã  la fois, TTL 1h)

---

## ConsÃ©quences

### âœ… Positives
1. **CoÃ»t zÃ©ro**: Aucun abonnement LLM (vs $25-50/mois OpenAI/Claude)
2. **ExplicabilitÃ©**: Chaque contributor identifiÃ© (source, rationale) â†’ confiance Reda
3. **Robustesse**: Fallback multi-models â†’ uptime ~95% (vs 99.9% OpenAI mais payant)
4. **Historisation**: Partitions `dt=YYYYMMDDHH` â†’ audit trail complet
5. **TestabilitÃ©**: Mock LLMClient â†’ tests reproductibles, CI rapide
6. **Ã‰volutivitÃ©**: Ajouter agents sans toucher arbitre

### âš ï¸ NÃ©gatives
1. **InstabilitÃ© g4f**: Providers parfois down/rate-limited â†’ retries requis
2. **Latency**: 30-60s total (4 agents sÃ©quentiels) vs 5-10s OpenAI
3. **QualitÃ© variable**: DeepSeek R1 > Qwen > GLM (pas uniforme)
4. **Pas de streaming**: RÃ©ponses complÃ¨tes seulement (pas de UX "typing...")
5. **DÃ©pendance communautÃ©**: Si g4f repo abandonnÃ© â†’ migration vers Ollama/OpenRouter

### ðŸ”§ Mitigations NÃ©gatives
- **Retry + fallback**: Si DeepSeek down â†’ Qwen (latency +5s acceptable)
- **Parallel agents**: Async calls (4 agents en parallÃ¨le) â†’ rÃ©duire 60s â†’ 20s (future)
- **Cache LLM**: Si inputs identiques derniÃ¨re heure â†’ rÃ©utiliser rÃ©ponse (future)
- **Monitoring**: Dashboard Observability affiche taux succÃ¨s/failure LLM
- **Plan B**: Ollama local (Llama 3.3 70B) si g4f instable > 50% Ã©checs/semaine

---

## Alternatives RejetÃ©es

### Alternative 1: OpenAI GPT-4
**Approche**: API officielle OpenAI

**Rejet**:
- **CoÃ»t**: $50/mois inacceptable pour budget Reda
- **Tracking**: OpenAI log prompts/outputs (confidentialitÃ©)
- **Lock-in**: DÃ©pendance fournisseur unique

### Alternative 2: Claude Sonnet via API
**Approche**: Anthropic API officielle

**Rejet**:
- **CoÃ»t**: $25/mois (meilleur que GPT-4 mais still payant)
- **Rate limits**: 50 req/min (vs g4f illimitÃ©)

### Alternative 3: Ollama Local (Llama 3.3 70B)
**Approche**: Run LLM localement (GPU)

**Rejet**:
- **Hardware**: GPU RTX 3090/4090 requis (~$1500)
- **RAM**: 48 GB+ pour 70B model
- **Ã‰lectricitÃ©**: 350W GPU 24/7 â†’ ~$30/mois
- **Note**: GardÃ© comme **Plan B** si g4f instable long terme

### Alternative 4: Prompt monolithique (single LLM call)
**Approche**: 1 seul prompt "rÃ©sume tout"

**Rejet**:
- **ExplicabilitÃ©**: Impossible identifier sources (black box)
- **Robustesse**: Si LLM hallucine, pas de cross-check
- **TestabilitÃ©**: Difficile mocker/valider

---

## ImplÃ©mentation

### Modules
- **`src/agents/llm/runtime.py`**: LLMClient wrapper g4f
  ```python
  class LLMClient:
      def __init__(self, provider: str = "g4f", model: str = "deepseek-ai/DeepSeek-R1-0528"):
          self.provider = provider
          self.model = model

      def generate(self, messages: List[Dict], json_mode: bool = True, temperature: float = 0.2, max_tokens: int = 2048, retries: int = 2) -> str:
          """Generate response with retry logic."""
          for attempt in range(retries + 1):
              try:
                  if self.provider == "g4f":
                      response = g4f.ChatCompletion.create(
                          model=self.model,
                          messages=messages,
                          temperature=temperature,
                          max_tokens=max_tokens
                      )
                      return response
              except Exception as e:
                  if attempt == retries:
                      raise
                  time.sleep(2 ** attempt)  # Backoff 2s, 4s
          raise RuntimeError("LLM generation failed after retries")
  ```

- **`src/agents/llm/toolkit.py`**: Functions pour agents
  ```python
  @toolkit_function
  def analyze_technique(top_n: int = 50) -> str:
      df = read_parquet_latest("data/forecast", "final.parquet")
      top = df.nlargest(top_n, "final_score")
      return json.dumps(top.to_dict("records"), ensure_ascii=False)

  @toolkit_function
  def analyze_macro() -> str:
      df = read_parquet_latest("data/macro/forecast", "macro_forecast.parquet")
      return json.dumps(df.tail(1).to_dict("records")[0], ensure_ascii=False)
  ```

- **`src/agents/llm/arbiter_agent.py`**: Main arbiter
  ```python
  def run_llm_summary() -> Dict:
      client = LLMClient(model="deepseek-ai/DeepSeek-R1-0528")

      prompt = f"""
      Tu es comitÃ© investissement. RÃ©concilie ces 4 analyses:

      1. Technique: {analyze_technique()}
      2. Macro: {analyze_macro()}
      3. Sentiment: {analyze_sentiment()}
      4. QualitÃ©: {analyze_quality()}

      GÃ©nÃ¨re JSON conformant schema LLMEnsembleSummary.
      """

      response = client.generate([{"role": "user", "content": prompt}], json_mode=True)
      summary = LLMEnsembleSummary(**json.loads(response))

      # Write partition
      dt = datetime.utcnow().strftime("%Y%m%d%H")
      outdir = Path("data/llm_summary") / f"dt={dt}"
      outdir.mkdir(parents=True, exist_ok=True)
      (outdir / "summary.json").write_text(summary.model_dump_json(indent=2))

      return summary.model_dump()
  ```

### Tests
- **`tests/llm/test_llm_summary.py`**: Mock LLMClient
  ```python
  def test_arbiter_with_mock():
      with patch("src.agents.llm.runtime.LLMClient.generate") as mock_gen:
          mock_gen.return_value = json.dumps({
              "regime": "expansion_modÃ©rÃ©e",
              "risk_level": "medium",
              "outlook_days_7": "positive",
              "outlook_days_30": "neutral",
              "key_drivers": ["Driver 1", "Driver 2", "Driver 3"],
              "contributors": [],
              "limits": []
          })

          summary = run_llm_summary()
          assert summary["regime"] == "expansion_modÃ©rÃ©e"
          mock_gen.assert_called_once()
  ```

---

## Validation

### CritÃ¨res de SuccÃ¨s
1. **Taux succÃ¨s > 90%**: Monitoring logs â†’ alert si < 90% last 7 days
2. **Latency < 90s**: P95 latency < 90s (4 agents + arbitre)
3. **ExplicabilitÃ©**: Chaque summary.json contient â‰¥ 3 contributors avec rationales
4. **Validation schema**: 100% summaries passent Pydantic validation

### Monitoring
- **Logs**: `artifacts/logs/llm_summary.log` (JSON lines)
- **Metrics**: Prometheus-style (duration, success/failure, model)
- **UI**: `/observability` affiche derniers 10 runs (timestamps, status, durÃ©e)

### Rollback Plan
Si taux Ã©chec g4f > 50% pendant 7 jours:
1. Migrate vers **OpenRouter** (g4f-like mais plus stable, ~$5/mois)
2. Long terme: Setup **Ollama local** (Llama 3.3 70B) si budget GPU acceptable

---

## RÃ©fÃ©rences

- **g4f Repo**: https://github.com/xtekky/gpt4free
- **DeepSeek R1**: https://huggingface.co/deepseek-ai/DeepSeek-R1
- **Pydantic Docs**: https://docs.pydantic.dev/
- **Issue initiale**: #78 "LLM summary MVP"

---

**RÃ©visions**:
- **v1.0** (2025-10-29): DÃ©cision initiale
