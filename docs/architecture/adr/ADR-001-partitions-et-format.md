# ADR-001 ‚Äî Partitions Temporelles Immutables

**Date**: 2025-10-29
**Statut**: ‚úÖ Accept√© (Impl√©ment√© Sprint 1)
**D√©cideurs**: √âquipe Dev + Reda
**R√©vision**: ‚Äî

---

## Contexte

L'application g√©n√®re des **forecasts quotidiens** (equity, commodities, macro) et des **synth√®ses LLM horaires**. Probl√®mes identifi√©s avec approche initiale "fichier unique":

1. **Perte d'historique**: R√©√©criture `forecast.parquet` ‚Üí donn√©es pr√©c√©dentes perdues
2. **Impossibilit√© backtests**: Besoin historique 252+ jours pour valider strat√©gies
3. **Concurrence agents**: 2 agents √©crivent simultan√©ment ‚Üí corruption fichier
4. **Debugging difficile**: Si bug, impossible savoir quand donn√©es g√©n√©r√©es

**Question**: Comment stocker donn√©es temporelles de fa√ßon **robuste, auditable, et extensible**?

---

## D√©cision

Adopter **partitions temporelles immutables** avec convention:

```
data/<domain>/dt=YYYYMMDD[HH]/<files>
```

### R√®gles
1. **Immutabilit√©**: Une fois partition `dt=YYYYMMDD` √©crite, **JAMAIS r√©√©crire**
2. **Granularit√©**:
   - **Quotidienne** (`YYYYMMDD`): forecasts, macro, quality, backtest
   - **Horaire** (`YYYYMMDDHH`): llm_summary (synth√®ses horaires)
3. **Lecture UI**: Toujours **derni√®re partition** (`latest_partition()` helper)
4. **Cr√©ation agents**: `mkdir -p data/<domain>/dt={datetime.utcnow().strftime("%Y%m%d")}` avant √©criture
5. **Nettoyage**: Optionnel, via cron (garder 90 derniers jours, archiver reste S3/glacier)

### Structure Type
```
data/
‚îú‚îÄ‚îÄ forecast/
‚îÇ   ‚îú‚îÄ‚îÄ dt=20251027/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forecasts.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ commodities.parquet
‚îÇ   ‚îú‚îÄ‚îÄ dt=20251028/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forecasts.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ commodities.parquet
‚îÇ   ‚îî‚îÄ‚îÄ dt=20251029/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ macro/
‚îÇ   ‚îî‚îÄ‚îÄ forecast/
‚îÇ       ‚îú‚îÄ‚îÄ dt=20251027/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ macro_forecast.json
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ macro_forecast.parquet
‚îÇ       ‚îî‚îÄ‚îÄ dt=20251028/
‚îÇ           ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ llm_summary/
‚îÇ   ‚îú‚îÄ‚îÄ dt=2025102914/  # 29 Oct 2025, 14h
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summary.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trace_raw.json
‚îÇ   ‚îî‚îÄ‚îÄ dt=2025102915/  # 15h
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ quality/
‚îÇ   ‚îú‚îÄ‚îÄ dt=20251027/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ freshness.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ report.json
‚îÇ   ‚îî‚îÄ‚îÄ dt=20251028/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ prices/
    ‚îî‚îÄ‚îÄ ticker=NVDA/  # Partition par ticker (pas dt, car historique 5y fixe)
        ‚îî‚îÄ‚îÄ prices.parquet
```

---

## Cons√©quences

### ‚úÖ Positives
1. **Historique complet**: Backtests pr√©cis, √©valuation forecasts vs r√©alisations
2. **Auditabilit√©**: Savoir exactement quand donn√©es g√©n√©r√©es (`dt=YYYYMMDD`)
3. **Concurrence safe**: Chaque agent √©crit sa propre partition ‚Üí pas de collision
4. **Rollback facile**: Si bug d√©tect√©, ignorer partition fautive, relancer agent
5. **Scaling**: Partitions facilement parall√©lisables (Spark, Dask si croissance data)
6. **Tests reproductibles**: Fixtures pointent vers partitions sp√©cifiques (ex: `dt=20250101`)

### ‚ö†Ô∏è N√©gatives
1. **Stockage croissant**: ~50 MB/jour forecasts ‚Üí 1.8 GB/an ‚Üí **acceptable** (disque 1 TB = 500 ans)
2. **Nettoyage requis**: Cron mensuel pour archiver/supprimer vieilles partitions (> 90j)
3. **Complexit√© lecture**: UI doit toujours lire "derni√®re partition" (helpers `read_parquet_latest()` requis)
4. **Partitions vides**: Si agent √©choue, partition dt cr√©√©e mais vide ‚Üí UI doit g√©rer gracefully

### üîß Mitigations N√©gatives
- **Helper `latest_partition()`**: Trouve automatiquement derni√®re partition (tri lexicographique `dt=` fonctionne)
- **Empty state UI**: Tous callbacks Dash g√®rent `df is None or df.empty` ‚Üí Alert FR ("Aucune donn√©e...")
- **Archivage automatique**: `make archive-old-partitions` (cron mensuel) ‚Üí S3 Glacier (co√ªt < $1/an)
- **Validation partition**: Agents √©crivent `.SUCCESS` flag apr√®s √©criture compl√®te ‚Üí UI ignore partitions sans flag

---

## Alternatives Rejet√©es

### Alternative 1: Fichier unique avec timestamp
**Approche**: `forecast_20251029.parquet`

**Rejet**:
- Impossible trouver "derni√®re version" efficacement (n√©cessite ls + tri)
- Pas de structure hi√©rarchique (tous fichiers m√™me niveau ‚Üí 365 fichiers/an)

### Alternative 2: Base de donn√©es SQL
**Approche**: PostgreSQL avec colonnes `generated_at TIMESTAMP`

**Rejet**:
- **Overhead**: Setup/maintenance DB
- **D√©pendance externe**: Agents doivent connect DB (vs simple write parquet)
- **Perf**: Pandas ‚Üí SQL slower que direct parquet write
- **Backup**: DB backup complexe vs simple `cp -r data/` ou S3 sync

### Alternative 3: Hive-style partitions (date/hour/)
**Approche**: `data/forecast/date=2025-10-29/hour=14/`

**Rejet**:
- Trop verbeux (2 niveaux vs 1)
- Format `date=YYYY-MM-DD` pas lexicographiquement triable (n√©cessite parsing)
- `dt=YYYYMMDDHH` plus compact, triable directement

---

## Impl√©mentation

### Modules
- **`src/tools/parquet_io.py`**: Helpers lecture partitions
  ```python
  def latest_partition(base_dir: str) -> Optional[Path]:
      """Trouve derni√®re partition dt= dans base_dir."""
      partitions = sorted([p for p in Path(base_dir).glob("dt=*") if p.is_dir()], reverse=True)
      return partitions[0] if partitions else None

  def read_parquet_latest(base_dir: str, filename: str) -> Optional[pd.DataFrame]:
      """Lit fichier parquet depuis derni√®re partition."""
      latest = latest_partition(base_dir)
      if latest and (latest / filename).exists():
          return pd.read_parquet(latest / filename)
      return None
  ```

### Pattern Agent (√©criture)
```python
from datetime import datetime
from pathlib import Path

def run_once():
    dt = datetime.utcnow().strftime("%Y%m%d")  # ou %Y%m%d%H si horaire
    outdir = Path("data/forecast") / f"dt={dt}"
    outdir.mkdir(parents=True, exist_ok=True)

    # Compute forecasts
    df = generate_forecasts()

    # Write parquet
    (outdir / "forecasts.parquet").write_parquet(df)

    # Success flag
    (outdir / ".SUCCESS").touch()
```

### Pattern UI (lecture)
```python
from src.tools.parquet_io import read_parquet_latest

def layout():
    df = read_parquet_latest("data/forecast", "final.parquet")
    if df is None or df.empty:
        return dbc.Alert("Aucune donn√©e de forecast disponible.", color="info")

    # Render table
    return dbc.Table.from_dataframe(df.head(10))
```

---

## Validation

### Tests
- **`tests/tools/test_parquet_io.py`**: Tests `latest_partition()`, `read_parquet_latest()`
  ```python
  def test_latest_partition_finds_newest(tmp_path):
      (tmp_path / "dt=20251027").mkdir()
      (tmp_path / "dt=20251029").mkdir()
      (tmp_path / "dt=20251028").mkdir()
      latest = latest_partition(str(tmp_path))
      assert latest.name == "dt=20251029"

  def test_read_parquet_latest_returns_none_if_missing(tmp_path):
      df = read_parquet_latest(str(tmp_path), "missing.parquet")
      assert df is None
  ```

### Monitoring
- **Freshness**: `data/quality/dt=*/freshness.json` track derni√®re partition par domain
- **UI Agents Status** (`/agents`): Affiche derni√®re `dt` par resource (forecasts, macro, llm_summary)

---

## Notes

- **Git ignore partitions**: `.gitignore` contient `data/*/dt=*` ‚Üí pas commit donn√©es (trop lourd)
- **CI fixtures**: Tests utilisent `tests/fixtures/data/forecast/dt=20250101/` (commit√©s, petits)
- **Nettoyage manuel**: `rm -rf data/forecast/dt={20241001..20241231}` (garde 2025 seulement)

---

## R√©f√©rences

- [Hive Partitioning](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables)
- [Parquet Best Practices](https://parquet.apache.org/docs/)
- Issue initiale: #42 "Historique forecasts perdu apr√®s chaque run"

---

**R√©visions**:
- **v1.0** (2025-10-29): D√©cision initiale
