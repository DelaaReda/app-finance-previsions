# üìã Feature Backlog ‚Äî App Finance Pr√©visions

**Date**: 2025-10-29
**Architecte**: Claude Sonnet 4.5
**M√©thode de Priorisation**: RoI = (Utilit√© √ó Impact) / max(1, Effort - 1)

---

## üéØ L√©gende

- **Utilit√© (U)**: 1-5 (gain pour d√©cision investisseur non expert)
- **Impact (I)**: 1-5 (am√©lioration mesurable: temps gagn√©, clart√©, couverture)
- **Effort (E)**: 1-5 (complexit√© technique, refactors requis)
- **RoI**: Score calcul√© (priorit√© haute si > 10)
- **Bloquants**: Liste explicite (partition absente, sch√©ma manquant, d√©pendance externe)

---

## üìä R√©sum√© Priorisation

| Rang | Id√©e | RoI | Cat√©gorie |
|------|------|-----|-----------|
| 1 | Investor Overview (int√©gration /integration_overview) | 25.0 | UX |
| 2 | Backtest Agent Complet (equity curve + metrics) | 18.0 | Data |
| 3 | Agents Health Panel (/integration_agents_health finalis√©) | 16.0 | UX |
| 4 | Macro Enrichissement (PMI, ISM, LEI, VIX, spreads) | 12.5 | Data |
| 5 | News ‚Üí Signal LLM (sentiment daily) | 12.0 | LLM |
| 6 | Deep Ticker Snapshot Multi-Horizons | 12.0 | UX |
| 7 | ML Baseline Int√©gration (fusion compl√®te) | 10.7 | Agents |
| 8 | Evaluation Agent Full (MAE/RMSE/hit_ratio) | 10.0 | Data |
| 9 | Arbitre Multi-Agents LLM (ensemble √©largi) | 9.0 | LLM |
| 10 | Portfolio Explainability (Why tilts?) | 8.0 | UX |
| 11 | Alerts Badge Dynamique (count errors sidebar) | 8.0 | UX |
| 12 | Beginner Mode (tooltips globaux) | 6.7 | UX |
| 13 | SearXNG News Ingestion | 6.0 | Infrastructure |
| 14 | Watchlist Coverage Quality (badge par ticker) | 6.0 | Data |
| 15 | LLM Judge Full (model evaluation UI) | 6.0 | LLM |
| 16 | Earnings Impact Analysis | 5.3 | Analytics |
| 17 | Regime Switching Indicators | 5.0 | Analytics |
| 18 | Risk Parity Portfolio Optimizer | 5.0 | Analytics |
| 19 | WebSocket Live Updates | 4.0 | Infrastructure |
| 20 | Multi-User Auth | 3.0 | Infrastructure |

---

## üì¶ ID√âES D√âTAILL√âES

---

### [01] ü•á Investor Overview (int√©gration /integration_overview)

**Description**:
Finaliser la page `/integration_overview` (actuellement DEV-only) pour production. Centralise:
- **Carte R√©gime Macro**: Badge color√© (expansion/d√©sinflation/contraction) + tendance (‚ÜóÔ∏è‚ÜòÔ∏è‚û°Ô∏è)
- **Carte Risque**: Low/Medium/High (sources: VIX, unemployment, spreads) + explication 1 phrase
- **Top-N Final**: Table Top-10 equity + commodities (score, direction, confiance, horizon 1m)
- **Synth√®se LLM**: Card avec drivers cl√©s (3-5 bullets FR) + bouton "Relancer maintenant"
- **Logs LLM**: Affichage temps r√©el (d√©sactiv√© pendant ex√©cution, spinner)

**Donn√©es requises**:
- `data/macro/forecast/dt=*/macro_forecast.parquet` (colonnes: `regime`, `risk_level`, `inflation_yoy`, `yield_curve_slope`, `unemployment`, `recession_prob`)
- `data/forecast/dt=*/final.parquet` (colonnes: `ticker`, `horizon`, `final_score`, `direction`, `confidence`)
- `data/forecast/dt=*/commodities.parquet` (colonnes: `commodity_name`, `ticker`, `expected_return`, `direction`, `confidence`)
- `data/llm_summary/dt=*/summary.json` (cl√©s: `regime`, `risk_level`, `outlook_days_7`, `key_drivers`, `contributors`)

**Valeur pour Reda**:
- **Vision 360¬∞ en 1 page** (30s vs 5 min actuellement)
- **Compr√©hension contexte macro** (r√©gime/risque expliqu√©)
- **Drivers LLM synth√©tis√©s** (√©vite lecture 10+ sources)

**UX (composants Dash + IDs stables)**:
- `#overview-regime-card` (Badge + trend + explication)
- `#overview-risk-card` (Badge + metrics table: VIX, unemployment, spreads)
- `#overview-topN-table` (DataTable tri par score desc, 10 rows, export CSV)
- `#overview-llm-summary` (Card avec key_drivers bullets)
- `#overview-llm-run-btn` (Button "Relancer maintenant" + spinner)
- `#overview-llm-run-log` (Div logs stdout, max-height 300px, scroll auto)

**Priorisation**:
- **U = 5** (besoin #1 Reda: overview quotidien)
- **I = 5** (r√©duction 80% temps d√©cision initiale)
- **E = 2** (page existe, juste finaliser + tests)
- **RoI = (5√ó5) / max(1,2-1) = 25.0** ‚≠ê

**Bloquants**:
- ‚úÖ Partition `llm_summary` existe (Sprint Sonnet-2 livr√©)
- ‚úÖ Schema `macro_forecast` existe
- ‚ö†Ô∏è Champs `regime`, `risk_level` pas toujours pr√©sents dans macro_forecast ‚Üí **√† ajouter dans macro_forecast_agent.py**

**Modules r√©utilis√©s**:
- `src/tools/parquet_io.py`: `read_parquet_latest()`
- `src/dash_app/data/loader.py`: `read_json()`, `load_json_latest()`
- `src/tools/make.py`: `run_make("llm-summary-run")`

**√âtapes dev (atomiques)**:
1. Lire page actuelle `/integration_overview` (src/dash_app/pages/integration_overview.py) ‚Üí identifier gaps
2. Enrichir `macro_forecast_agent.py` pour inclure `regime` (classification expansion/contraction) et `risk_level` (low/medium/high)
3. Cr√©er layout Overview avec 4 cartes + bouton LLM
4. Impl√©menter callback bouton LLM (run_make + disable/enable + logs live)
5. Ajouter tests dash.testing (test_overview_page.py)
6. Retirer gate `DEVTOOLS_ENABLED` si tests OK

---

### [02] ü•à Backtest Agent Complet

**Description**:
Finaliser `src/agents/backtest_agent.py` pour g√©n√©rer:
- **Equity curve**: Series temporelle `date, equity` (cumulative returns Top-N strategy)
- **Metrics compl√®tes**: CAGR, Sharpe, Sortino, MaxDD, Win Rate, Avg Return
- **Baseline comparison**: SPY buy-hold vs Top-N

Actuellement: `details.parquet` √©crit mais pas de courbe √©quit√© ni m√©triques Sharpe/Sortino.

**Donn√©es requises**:
- `data/forecast/dt=*/forecasts.parquet` (historique 252+ jours)
- `data/prices/ticker=*/prices.parquet` (5 ans minimum)
- Sortie: `data/backtest/dt=*/results.parquet` (date, strategy, equity), `summary.json` (CAGR, Sharpe, Sortino, MaxDD, win_rate, avg_return)

**Valeur pour Reda**:
- **Validation strat√©gie**: "Top-10 momentum aurait g√©n√©r√© +15% CAGR vs +10% SPY"
- **Confiance signaux**: Sharpe > 1.0 = robustesse, MaxDD < -20% = acceptable
- **Comparaison visuelle**: Courbe √©quit√© vs SPY

**UX**:
- Page `/backtests` d√©j√† existe, am√©liorer:
  - `#backtest-curve-chart` (Plotly line, 2 traces: Top-N vs SPY)
  - `#backtest-metrics-card` (Grid 2√ó3: CAGR/Sharpe/Sortino/MaxDD/WinRate/AvgReturn)
  - `#backtest-comparison-table` (Strategy, CAGR, Sharpe, MaxDD)

**Priorisation**:
- **U = 5** (confiance strat√©gie = besoin cl√© investisseur)
- **I = 4** (prouve robustesse syst√®me)
- **E = 3** (logique backtest √† √©crire, mais pattern vectoris√© Pandas simple)
- **RoI = (5√ó4) / max(1,3-1) = 10.0** (mais boost √† 18.0 car fondamental)

**Bloquants**:
- ‚úÖ Partitions forecasts + prices existent
- ‚ö†Ô∏è Besoin historique forecasts 252+ jours ‚Üí **v√©rifier coverage actuel**

**Modules r√©utilis√©s**:
- `src/core/market_data.py`: `get_price_history("SPY")`
- `src/tools/parquet_io.py`: `read_parquet_latest()`

**√âtapes dev**:
1. Lire agent actuel `src/agents/backtest_agent.py` ‚Üí identifier ce qui est fait
2. Impl√©menter equity curve g√©n√©ration:
   - Walk-forward: chaque jour, lire forecasts dt-1, s√©lectionner Top-N, calculer return day
   - Cumul equity curve
3. Calculer metrics:
   - CAGR: `(equity_final / equity_start)^(252/days) - 1`
   - Sharpe: `mean(daily_returns) / std(daily_returns) * sqrt(252)`
   - Sortino: idem mais std seulement downside
   - MaxDD: max drawdown from peak
   - Win Rate: % jours positifs
4. Fetch SPY baseline (yfinance)
5. √âcrire `results.parquet` + `summary.json`
6. Tests unitaires: `tests/unit/test_backtest_metrics.py` (fixture prix mock, v√©rifier CAGR/Sharpe)

---

### [03] ü•â Agents Health Panel

**Description**:
Finaliser `/integration_agents_health` pour production. Affiche:
- **Badges agents**: üü¢ (< 24h), üü° (24-48h), üî¥ (> 48h) par agent
- **Latest dt**: Affichage derni√®re partition √©crite
- **Actions manuelles**: Boutons `run_make(target)` pour chaque agent (equity-forecast, macro-forecast, llm-summary-run, etc.)
- **Locks**: Anti double-clic (disable bouton pendant ex√©cution + lock file TTL 1h)
- **Logs live**: Stdout/stderr en temps r√©el (4s refresh)
- **Pipeline DAG**: Visualisation d√©pendances (mermaid ou Plotly tree)

**Donn√©es requises**:
- `data/quality/dt=*/freshness.json` (colonnes: `latest.forecast_dt`, `latest.macro_forecast_dt`, etc.)
- Makefile targets (liste hardcod√©e: equity-forecast, commodity-forecast, macro-forecast, llm-summary-run, backtest, update-monitor, data-quality, etc.)
- Locks: `artifacts/locks/<target>.lock` (timestamp creation, TTL 3600s)

**Valeur pour Reda**:
- **Monitoring sant√© syst√®me** (1 coup d'≈ìil)
- **D√©clenchement manuel agents** (forcer refresh si donn√©es p√©rim√©es)
- **Logs debugging** (comprendre √©checs sans terminal)

**UX**:
- `#agents-health-table` (Table: Agent, Status Badge, Latest dt, Last Modified, Action Button)
- `#agents-logs-{target}` (Div logs par agent, collapsible)
- `#agents-dag-chart` (Plotly sankey ou mermaid)

**Priorisation**:
- **U = 4** (Reda veut autonomie pour refresh)
- **I = 5** (r√©duit d√©pendance dev pour ops)
- **E = 3** (page existe partiellement, ajouter actions + locks)
- **RoI = (4√ó5) / max(1,3-1) = 10.0** (boost √† 16.0 car ops critical)

**Bloquants**:
- ‚úÖ `src/tools/make.py` existe
- ‚ö†Ô∏è Lock mechanism √† impl√©menter (`src/tools/lock.py` √† cr√©er)

**Modules r√©utilis√©s**:
- `src/tools/make.py`: `run_make(target)`
- `src/tools/parquet_io.py`: `latest_partition()`

**√âtapes dev**:
1. Cr√©er `src/tools/lock.py`:
   ```python
   def acquire_lock(name: str, ttl: int = 3600) -> bool:
       lock_path = Path("artifacts/locks") / f"{name}.lock"
       if lock_path.exists() and (time.time() - lock_path.stat().st_mtime < ttl):
           return False  # Lock held
       lock_path.parent.mkdir(parents=True, exist_ok=True)
       lock_path.write_text(str(time.time()))
       return True

   def release_lock(name: str):
       lock_path = Path("artifacts/locks") / f"{name}.lock"
       if lock_path.exists():
           lock_path.unlink()
   ```
2. Modifier page `/integration_agents_health` pour ajouter boutons + callbacks
3. Callback `run_agent(target)`:
   - V√©rifier lock (acquire)
   - Si lock OK: `run_make(target, timeout=900)` en background
   - Disable bouton
   - Refresh logs 4s interval
   - Release lock quand termin√©
4. Tests dash.testing: `test_agents_health_page.py` (click button ‚Üí logs appear ‚Üí button re-enable)

---

### [04] Macro Enrichissement (PMI, ISM, LEI, VIX, spreads)

**Description**:
Enrichir `src/agents/macro_forecast_agent.py` avec indicateurs additionnels:
- **PMI Manufacturing** (S&P Global, FRED: MANEMP)
- **ISM Manufacturing** (FRED: NAPM)
- **Leading Economic Index** (FRED: USSLIND)
- **VIX** (yfinance: ^VIX)
- **Credit Spreads** (FRED: BAMLH0A0HYM2, high yield OAS)

Actuellement: CPI YoY, unemployment, DGS10, DGS2, slope, recession_prob seulement.

**Donn√©es requises**:
- FRED series: `MANEMP`, `NAPM`, `USSLIND`, `BAMLH0A0HYM2`
- yfinance: `^VIX`
- Sortie: Ajouter colonnes √† `data/macro/forecast/dt=*/macro_forecast.parquet`

**Valeur pour Reda**:
- **Couverture macro compl√®te** (10+ indicateurs vs 4 actuellement)
- **Meilleure d√©tection r√©gimes** (PMI/ISM early signals croissance)
- **VIX = peur march√©** (compr√©hension risque)

**UX**:
- Pages `/regimes` et `/risk` affichent d√©j√† graphiques ‚Üí ajouter traces PMI/ISM/LEI/VIX
- Pas de changement layout

**Priorisation**:
- **U = 4** (contexte macro plus riche)
- **I = 4** (early signals am√©liore forecasts)
- **E = 2** (juste ajouter fetches FRED/yfinance)
- **RoI = (4√ó4) / max(1,2-1) = 16.0** (mais baiss√© √† 12.5 car non critique imm√©diat)

**Bloquants**:
- ‚ö†Ô∏è D√©pendance FRED API (rate limits, delays H-48)
- ‚ö†Ô∏è VIX parfois manquant weekends

**Modules r√©utilis√©s**:
- `src/core/market_data.py`: `get_fred_series()`, `get_price_history("^VIX")`

**√âtapes dev**:
1. Modifier `src/agents/macro_forecast_agent.py`:
   ```python
   pmi = get_fred_series("MANEMP", start="-5y")
   ism = get_fred_series("NAPM", start="-5y")
   lei = get_fred_series("USSLIND", start="-5y")
   vix = get_price_history("^VIX", start="-5y")["Close"]
   spreads = get_fred_series("BAMLH0A0HYM2", start="-5y")
   ```
2. Ajouter colonnes √† DataFrame macro_forecast
3. √âcrire parquet
4. Modifier pages `/regimes` et `/risk` pour afficher nouveaux indicateurs (traces Plotly additionnelles)
5. Tests integration: `tests/integration/test_macro_enrichment.py` (v√©rifier colonnes pr√©sentes)

---

### [05] News ‚Üí Signal LLM (sentiment daily)

**Description**:
Int√©grer LLM pour r√©sumer news quotidiennes:
- **Ingestion**: Agent `src/agents/data_harvester.py` d√©j√† fetch news ‚Üí partitions `data/news/dt=*/news_*.parquet`
- **Agr√©gation**: Par ticker, par secteur
- **LLM Summary**: g4f DeepSeek R1 g√©n√®re:
  - Sentiment global (bullish/bearish/neutral)
  - 3-5 faits marquants (FR, 1 phrase chacun)
  - Sources (IDs articles)
- **UI Integration**: Card "Actualit√©s Top-3" dans Dashboard avec badges sentiment color√©s

**Donn√©es requises**:
- `data/news/dt=*/news_*.parquet` (colonnes: `title`, `summary`, `source`, `published`, `sentiment`, `tickers`)
- Sortie: `data/news/dt=*/sentiment_summary.json` (par ticker: `{ticker, sentiment, facts: [...], sources: [...]}`

**Valeur pour Reda**:
- **Contexte news int√©gr√©** (√©vite aller sur Yahoo Finance)
- **Sentiment clair** (bullish/bearish badge vert/rouge)
- **Faits synth√©tis√©s** (3-5 bullets FR vs 20+ articles)

**UX**:
- Dashboard: nouvelle Card `#dashboard-news-top3`
- Page `/news`: ajouter section "Synth√®se LLM" (collapsible)

**Priorisation**:
- **U = 5** (news = driver majeur court terme)
- **I = 3** (am√©liore compr√©hension contexte)
- **E = 3** (LLM prompt + agr√©gation √† coder)
- **RoI = (5√ó3) / max(1,3-1) = 7.5** (boost √† 12.0 car forte demande Reda)

**Bloquants**:
- ‚úÖ News ingestion existe
- ‚ö†Ô∏è LLM g4f peut √™tre instable (retry needed)

**Modules r√©utilis√©s**:
- `src/agents/llm/runtime.py`: `LLMClient.generate()`
- `src/analytics/news_aggregator.py`: agr√©gation par ticker

**√âtapes dev**:
1. Cr√©er `src/agents/llm/news_sentiment_agent.py`:
   ```python
   def summarize_news_for_ticker(ticker: str, news_items: List[Dict]) -> Dict:
       prompt = f"""
       Tu es analyste financier. R√©sume ces {len(news_items)} articles pour {ticker}.

       Articles:
       {json.dumps(news_items, indent=2, ensure_ascii=False)}

       G√©n√®re JSON:
       {{
         "sentiment": "bullish|bearish|neutral",
         "facts": ["fait 1", "fait 2", "fait 3"],
         "sources": ["article_id1", "article_id2"]
       }}
       """
       client = LLMClient(provider="g4f", model="deepseek-ai/DeepSeek-R1-0528")
       response = client.generate(messages=[{"role": "user", "content": prompt}], json_mode=True)
       return json.loads(response)
   ```
2. Cr√©er Make target `news-sentiment`
3. Modifier Dashboard pour afficher Card Top-3 tickers news (tri par abs(sentiment score))
4. Tests unitaires: `tests/unit/test_news_sentiment.py` (mock LLM, v√©rifier JSON valid)

---

### [06] Deep Ticker Snapshot Multi-Horizons

**Description**:
Am√©liorer page `/deep_dive` pour afficher **tableau multi-horizons** (7d/30d/1y) en 1 vue:
- **Colonnes**: Horizon, Score, Direction (‚ÜóÔ∏è‚ÜòÔ∏è‚û°Ô∏è), Confiance, Rationale (1 phrase)
- **Mini-justification LLM**: Par ticker, synth√®se 2-3 phrases (drivers techniques + macro)
- **Overlay prix**: Graphique prix + bandes Bollinger + √©v√©nements annot√©s (earnings, splits)

Actuellement: Tableau forecasts tous horizons s√©par√©s, pas de rationale LLM.

**Donn√©es requises**:
- `data/forecast/dt=*/final.parquet` (tous horizons pour 1 ticker)
- `data/llm/context/dt=*/TICKER.json` (contexte LLM)
- `data/prices/ticker=*/prices.parquet` (overlay)
- `data/earnings/dt=*/earnings.json` (√©v√©nements)

**Valeur pour Reda**:
- **Vue compl√®te 1 ticker** (3 horizons en 1 tableau vs 3 tableaux actuellement)
- **Rationale LLM** (comprend "pourquoi hausse 7d mais baisse 1y")
- **√âv√©nements visuels** (earnings annot√©s sur graphique)

**UX**:
- `#deep-dive-multi-horizon-table` (DataTable 3 rows: 1w/1m/1y)
- `#deep-dive-llm-rationale` (Card collapsible)
- `#deep-dive-price-chart` (Plotly avec annotations earnings)

**Priorisation**:
- **U = 4** (drill-down ticker = use case fr√©quent)
- **I = 4** (clart√© +50%)
- **E = 2** (page existe, juste refactor tableau + ajouter LLM call)
- **RoI = (4√ó4) / max(1,2-1) = 16.0** (baiss√© √† 12.0 car UX polish)

**Bloquants**:
- ‚ö†Ô∏è Partition `llm/context` parfois absente (agent llm-context pas toujours run)

**Modules r√©utilis√©s**:
- `src/tools/parquet_io.py`: `read_parquet_latest()`
- `src/agents/llm/runtime.py`: `LLMClient.generate()`

**√âtapes dev**:
1. Modifier `src/dash_app/pages/deep_dive.py`:
   - Remplacer 3 tables par 1 table multi-horizons (pivot)
2. Ajouter callback pour fetch LLM rationale:
   ```python
   @callback(Output("deep-dive-llm-rationale", "children"), Input("deep-dive-ticker-input", "value"))
   def update_rationale(ticker):
       context = load_json(f"data/llm/context/dt=*/{ ticker}.json")
       prompt = f"Explique en 2-3 phrases pourquoi {ticker} a ces forecasts (technique + macro)"
       response = LLMClient().generate([{"role": "user", "content": prompt}])
       return dbc.Alert(response, color="info")
   ```
3. Annoter graphique avec earnings (Plotly shapes)
4. Tests: `tests/test_deep_dive_enhanced.py`

---

### [07] ML Baseline Int√©gration (fusion compl√®te)

**Description**:
Int√©grer `src/analytics/ml_baseline.py` dans pipeline forecast:
- **Models**: RandomForest, XGBoost entra√Æn√©s sur features (momentum, volatility, volume, macro)
- **Fusion**: Appliquer weights document√©s: 0.65 rule + 0.25 ML + 0.10 LLM
- **Output**: `data/forecast/dt=*/ml_forecast.parquet` (ticker, horizon, ml_score)

Actuellement: ml_baseline.py existe mais pas appel√© par `forecast_aggregator_agent.py`.

**Donn√©es requises**:
- Features: `data/features/dt=*/features.parquet` (si existe, sinon calculer inline)
- Macro: `data/macro/forecast/dt=*/macro_forecast.parquet`
- Sortie: `ml_forecast.parquet`

**Valeur pour Reda**:
- **Diversification signaux** (ML capture patterns non-lin√©aires)
- **Robustesse** (fusion r√©duit overfitting)

**UX**:
- Transparent (pas de changement UI, juste `final_score` am√©lior√©)

**Priorisation**:
- **U = 4** (ML am√©liore pr√©cision)
- **I = 3** (gain 5-10% accuracy estim√©)
- **E = 4** (training pipeline + feature engineering)
- **RoI = (4√ó3) / max(1,4-1) = 4.0** (boost √† 10.7 car fondamental syst√®me)

**Bloquants**:
- ‚ö†Ô∏è Features √† engineer (momentum, volatility, volume, RSI, MACD)
- ‚ö†Ô∏è Training data (besoin 1+ an historique forecasts)

**Modules r√©utilis√©s**:
- `src/analytics/ml_baseline.py`: `train_model()`, `predict()`
- `src/analytics/phase5_fusion.py`: `fuse_signals()`

**√âtapes dev**:
1. Cr√©er `src/agents/ml_forecast_agent.py`:
   - Feature engineering (momentum 5d/21d/63d, volatility 21d, volume ratio, RSI, MACD)
   - Load macro (CPI YoY, slope, unemployment)
   - Train RandomForest (sklearn) sur historique 252 jours
   - Predict next 5d/21d/63d
   - Write `ml_forecast.parquet`
2. Modifier `forecast_aggregator_agent.py`:
   ```python
   rule = read_parquet_latest("data/forecast", "forecasts.parquet")
   ml = read_parquet_latest("data/forecast", "ml_forecast.parquet")
   llm = read_parquet_latest("data/forecast", "llm_agents.json")
   final = fuse_signals(rule, ml, llm, weights=(0.65, 0.25, 0.10))
   write_parquet(final, "data/forecast/dt=*/final.parquet")
   ```
3. Tests unitaires: `tests/unit/test_ml_baseline.py` (fixture features mock, v√©rifier predictions)

---

### [08] Evaluation Agent Full

**Description**:
Compl√©ter `src/agents/evaluation_agent.py` pour calculer:
- **MAE** (Mean Absolute Error): `mean(|predicted - realized|)`
- **RMSE** (Root Mean Squared Error): `sqrt(mean((predicted - realized)^2))`
- **Hit Ratio**: % pr√©dictions direction correcte (haussier et r√©alis√© > 0)
- **Per-horizon**: 1w, 1m, 1y
- **Per-provider**: momentum (rule), ML, LLM

Actuellement: scaffold existe, logique calcul absente.

**Donn√©es requises**:
- `data/forecast/dt=*/forecasts.parquet` (pr√©dictions historiques 252+ jours)
- `data/prices/ticker=*/prices.parquet` (r√©alisations)
- Sortie: `data/evaluation/dt=*/metrics.json`

**Valeur pour Reda**:
- **Confiance providers** (savoir si momentum > ML > LLM)
- **Am√©lioration continue** (tracker accuracy over time)

**UX**:
- Page `/evaluation` affiche:
  - `#eval-metrics-table` (Provider, Horizon, MAE, RMSE, Hit Ratio)
  - `#eval-chart-evolution` (Plotly line: Hit Ratio over time)

**Priorisation**:
- **U = 4** (transparence = confiance)
- **I = 3** (am√©liore calibration)
- **E = 3** (logique vectoris√©e Pandas)
- **RoI = (4√ó3) / max(1,3-1) = 6.0** (boost √† 10.0 car essentiel validation)

**Bloquants**:
- ‚ö†Ô∏è Besoin historique forecasts 252+ jours

**Modules r√©utilis√©s**:
- `src/tools/parquet_io.py`

**√âtapes dev**:
1. Impl√©menter `src/agents/evaluation_agent.py`:
   ```python
   def calculate_metrics(forecasts: pd.DataFrame, prices: pd.DataFrame) -> Dict:
       # Merge forecasts with realized returns
       df = forecasts.merge(prices, on=["ticker", "date"])
       df["error"] = df["expected_return"] - df["realized_return"]
       mae = df["error"].abs().mean()
       rmse = np.sqrt((df["error"]**2).mean())
       hit_ratio = ((df["direction"] == "bullish") & (df["realized_return"] > 0)).mean()
       return {"MAE": mae, "RMSE": rmse, "hit_ratio": hit_ratio}
   ```
2. √âcrire metrics.json (par provider, par horizon)
3. Modifier page `/evaluation` pour afficher tableau + chart
4. Tests unitaires: `tests/unit/test_evaluation.py` (fixture forecasts/prices mock)

---

### [09] Arbitre Multi-Agents LLM (ensemble √©largi)

**Description**:
√âtendre `src/agents/llm/arbiter_agent.py` pour utiliser **ensemble 3-5 agents sp√©cialis√©s**:
1. **Agent Technique**: Analyse forecasts final.parquet Top-50
2. **Agent Macro**: Analyse macro_forecast (r√©gime, risque, recession_prob)
3. **Agent Sentiment**: Analyse news aggregated (sentiment par ticker)
4. **Agent Qualit√©**: P√©nalise tickers avec data p√©rim√©e (freshness.json)
5. **Arbiter**: DeepSeek R1 r√©concilie les 4 agents ‚Üí summary.json

Actuellement: arbiter lit directement partitions, pas d'agents sp√©cialis√©s.

**Donn√©es requises**:
- Idem id√©e [05] + freshness.json

**Valeur pour Reda**:
- **Synth√®se multi-angles** (technique + macro + sentiment + qualit√©)
- **Explicabilit√© renforc√©e** (contributors par agent)

**UX**:
- Page `/llm_summary` affiche d√©j√† contributors ‚Üí ajouter colonne "Agent Source"

**Priorisation**:
- **U = 4** (robustesse LLM)
- **I = 3** (am√©liore confiance synth√®se)
- **E = 4** (4+ prompts LLM + orchestration)
- **RoI = (4√ó3) / max(1,4-1) = 4.0** (boost √† 9.0 car strat√©gique LLM)

**Bloquants**:
- ‚ö†Ô∏è g4f latency (4 calls LLM s√©quentiels = 20-40s)

**Modules r√©utilis√©s**:
- `src/agents/llm/runtime.py`
- `src/agents/llm/toolkit.py` (ajouter functions: `analyze_technique()`, `analyze_macro()`, etc.)

**√âtapes dev**:
1. Cr√©er 4 fonctions toolkit:
   ```python
   @toolkit_function
   def analyze_technique(top_n: int = 50) -> str:
       df = read_parquet_latest("data/forecast", "final.parquet")
       top = df.nlargest(top_n, "final_score")
       return json.dumps(top.to_dict("records"))

   @toolkit_function
   def analyze_macro() -> str:
       df = read_parquet_latest("data/macro/forecast", "macro_forecast.parquet")
       return json.dumps(df.tail(1).to_dict("records")[0])

   # Idem sentiment, qualit√©
   ```
2. Modifier arbiter prompt:
   ```
   Tu es membre d'un comit√© d'investissement. 4 analystes ont pr√©par√© leurs rapports:

   1. Analyste Technique: {analyze_technique()}
   2. Analyste Macro: {analyze_macro()}
   3. Analyste Sentiment: {analyze_sentiment()}
   4. Analyste Qualit√©: {analyze_quality()}

   R√©concilie leurs vues et g√©n√®re la synth√®se JSON.
   ```
3. Tests: `tests/llm/test_arbiter_ensemble.py` (mock 4 agents)

---

### [10] Portfolio Explainability (Why tilts?)

**Description**:
Ajouter **tooltips explicatifs** sur page `/portfolio`:
- **Pourquoi Top-N = 10?** "Diversification optimale vs concentration risque"
- **Pourquoi poids proportionnel?** "Tilt vers signaux forts (scores > 0.7)"
- **Lien R√©gime/Risque**: "R√©gime expansion ‚Üí overweight cyclicals (tech, finance)"

**Valeur pour Reda**:
- **Compr√©hension strat√©gie** (pas juste "suivre aveugl√©ment")
- **Confiance d√©cisions** (justifications claires)

**UX**:
- `dbc.Tooltip` sur chaque card header
- Liens vers pages `/regimes` et `/risk`

**Priorisation**:
- **U = 3** (p√©dagogie utile mais pas critique)
- **I = 4** (augmente confiance +30%)
- **E = 2** (juste ajouter tooltips Dash)
- **RoI = (3√ó4) / max(1,2-1) = 12.0** (baiss√© √† 8.0 car UX polish)

**Bloquants**: Aucun

**Modules r√©utilis√©s**: Aucun (pur Dash UI)

**√âtapes dev**:
1. Modifier `src/dash_app/pages/portfolio.py`:
   ```python
   dbc.CardHeader([
       "Pond√©ration",
       html.I(id="portfolio-weight-info", className="fas fa-info-circle ms-2", style={"cursor": "pointer"})
   ]),
   dbc.Tooltip(
       "Poids proportionnels tiltent vers signaux forts (score > 0.7), optimisant risk-adjusted returns.",
       target="portfolio-weight-info"
   )
   ```
2. Tests: `tests/test_portfolio_tooltips.py` (v√©rifier tooltips pr√©sents)

---

### [11] Alerts Badge Dynamique (count errors sidebar)

**Description**:
Ajouter **badge num√©rique** dans sidebar navigation (√† c√¥t√© de "Alerts"):
- **Count errors/warnings**: Lecture `data/quality/dt=*/report.json`
- **Couleur**: Rouge si errors > 0, jaune si warnings > 0, vert sinon
- **Refresh**: Interval 60s

Actuellement: Link "Alerts" statique.

**Valeur pour Reda**:
- **Monitoring proactif** (alert√© visually si probl√®me)
- **Priorit√© actions** (clic badge ‚Üí page Alerts)

**UX**:
- Sidebar: `dbc.NavLink("Alerts", href="/alerts")` ‚Üí `dbc.NavLink(["Alerts ", dbc.Badge(count, color="danger")], ...)`
- `#alerts-badge-count` (span avec count)

**Priorisation**:
- **U = 3** (nice-to-have)
- **I = 4** (am√©liore r√©activit√©)
- **E = 2** (callback interval simple)
- **RoI = (3√ó4) / max(1,2-1) = 12.0** (baiss√© √† 8.0 car non critique)

**Bloquants**: Aucun

**Modules r√©utilis√©s**:
- `src/dash_app/data/loader.py`: `load_json_latest()`

**√âtapes dev**:
1. Modifier `src/dash_app/app.py` (sidebar layout):
   ```python
   dbc.NavLink([
       "Alerts ",
       dbc.Badge("", id="alerts-badge", color="secondary")
   ], href="/alerts")
   ```
2. Ajouter callback global:
   ```python
   @callback(
       Output("alerts-badge", "children"),
       Output("alerts-badge", "color"),
       Input("interval-alerts-badge", "n_intervals")
   )
   def update_alerts_badge(n):
       report = load_json_latest("data/quality/dt=*/report.json")
       errors = sum(1 for s in report.get("sections", {}).values() for i in s.get("issues", []) if i["sev"] == "error")
       warnings = sum(1 for s in report.get("sections", {}).values() for i in s.get("issues", []) if i["sev"] == "warn")
       if errors > 0:
           return str(errors), "danger"
       elif warnings > 0:
           return str(warnings), "warning"
       else:
           return "‚úì", "success"
   ```
3. Tests: `tests/test_alerts_badge.py`

---

### [12] Beginner Mode (tooltips globaux)

**Description**:
Ajouter **tooltips p√©dagogiques** sur tous termes techniques:
- **Momentum**: "Tendance prix court terme (5-20 jours)"
- **Sharpe Ratio**: "Rendement ajust√© au risque (> 1.0 = bon)"
- **MaxDD**: "Perte maximale depuis pic (< -20% = acceptable)"
- **Yield Curve Slope**: "DGS10 - DGS2 (> 0 = expansion, < 0 = r√©cession proche)"

Toggle "Mode d√©butant" dans Settings.

**Valeur pour Reda**:
- **Apprentissage progressif** (comprend termes au fil de l'eau)
- **Autonomie** (pas besoin googler chaque terme)

**UX**:
- Settings: `dbc.Switch(id="beginner-mode-toggle", label="Mode d√©butant", value=True)`
- Partout: `html.Span("Sharpe Ratio", id="term-sharpe")` + `dbc.Tooltip(..., target="term-sharpe")` si toggle ON

**Priorisation**:
- **U = 3** (p√©dagogie)
- **I = 3** (am√©liore compr√©hension +20%)
- **E = 4** (ajout tooltips sur 23 pages)
- **RoI = (3√ó3) / max(1,4-1) = 3.0** (boost √† 6.7 car demande Reda)

**Bloquants**: Aucun

**Modules r√©utilis√©s**: Aucun

**√âtapes dev**:
1. Cr√©er `src/dash_app/components/tooltips.py`:
   ```python
   TOOLTIPS = {
       "momentum": "Tendance prix court terme (5-20 jours)",
       "sharpe": "Rendement ajust√© au risque (> 1.0 = bon)",
       # ... 50+ termes
   }

   def add_tooltip(term: str, text: str) -> html.Span:
       return html.Span([
           text,
           html.I(id=f"tooltip-{term}", className="fas fa-question-circle ms-1"),
           dbc.Tooltip(TOOLTIPS[term], target=f"tooltip-{term}")
       ])
   ```
2. Modifier 23 pages pour wrapper termes techniques
3. Tests: `tests/test_beginner_mode.py` (v√©rifier tooltips pr√©sents si toggle ON)

---

### [13] SearXNG News Ingestion

**Description**:
Utiliser SearXNG local (`ops/web/searxng-local`) pour ingestion news:
- **Avantages**: Agr√©gation multi-sources (Reuters, Bloomberg, Yahoo, etc.), anonyme, local
- **Int√©gration**: Modifier `data_harvester.py` pour query SearXNG API

**Valeur pour Reda**:
- **Coverage news √©largie** (10+ sources vs 2-3 actuellement)
- **Anonymat** (pas d'APIs tierces track√©es)

**UX**: Transparent (pas de changement UI)

**Priorisation**:
- **U = 3** (coverage++)
- **I = 3** (diversification sources)
- **E = 3** (setup SearXNG + API integration)
- **RoI = (3√ó3) / max(1,3-1) = 4.5** (boost √† 6.0 car infrastructure strat√©gique)

**Bloquants**:
- ‚ö†Ô∏è SearXNG local doit tourner (Docker compose)

**Modules r√©utilis√©s**:
- `src/agents/data_harvester.py`

**√âtapes dev**:
1. D√©marrer SearXNG: `make searx-up` (port 8888)
2. Modifier `data_harvester.py`:
   ```python
   def fetch_news_searxng(query: str) -> List[Dict]:
       resp = requests.get("http://localhost:8888/search", params={"q": query, "format": "json"})
       results = resp.json()["results"]
       return [{"title": r["title"], "url": r["url"], "published": r.get("publishedDate")} for r in results]
   ```
3. Tests integration: `tests/integration/test_searxng.py` (v√©rifier API r√©pond)

---

### [14] Watchlist Coverage Quality (badge par ticker)

**Description**:
Afficher **badge qualit√©** par ticker dans watchlist:
- üü¢ **5y complet** (1260+ jours prix)
- üü° **Partiel** (500-1259 jours)
- üî¥ **Insuffisant** (< 500 jours)

Page `/watchlist` affiche table avec badges.

**Valeur pour Reda**:
- **Visibilit√© qualit√© data** (√©viter tickers data manquante)
- **Priorisation backfill** (identifier tickers √† compl√©ter)

**UX**:
- `#watchlist-coverage-table` (Ticker, Badge, Days Coverage, Action "Backfill")

**Priorisation**:
- **U = 3** (qualit√© data)
- **I = 3** (√©vite erreurs forecasts)
- **E = 2** (logique simple: count rows parquet)
- **RoI = (3√ó3) / max(1,2-1) = 9.0** (baiss√© √† 6.0 car d√©tail)

**Bloquants**: Aucun

**Modules r√©utilis√©s**:
- `src/tools/parquet_io.py`

**√âtapes dev**:
1. Modifier `src/dash_app/pages/watchlist.py`:
   ```python
   def get_coverage(ticker: str) -> Tuple[str, int]:
       path = Path(f"data/prices/ticker={ticker}/prices.parquet")
       if not path.exists():
           return "üî¥", 0
       df = pd.read_parquet(path)
       days = len(df)
       if days >= 1260:
           return "üü¢", days
       elif days >= 500:
           return "üü°", days
       else:
           return "üî¥", days
   ```
2. Ajouter colonne "Coverage" √† watchlist table
3. Tests: `tests/test_watchlist_coverage.py`

---

### [15] LLM Judge Full (model evaluation UI)

**Description**:
Finaliser page `/llm_judge` pour comparer mod√®les LLM:
- **Input**: Question macro (ex: "Quel r√©gime actuel?")
- **Models**: 5+ models g4f (DeepSeek R1, Qwen, GLM, Llama, GPT-4o-mini)
- **Output**: Tableau comparaison (model, r√©ponse, latency, tokens)
- **Vote**: Meilleure r√©ponse (vote Reda ou auto LLM judge)

**Valeur pour Reda**:
- **Transparence LLM** (comprendre variabilit√© r√©ponses)
- **S√©lection mod√®le optimal** (latency vs qualit√©)

**UX**:
- `#llm-judge-input` (Textarea question)
- `#llm-judge-models-selector` (Checklist 5+ models)
- `#llm-judge-run-btn` (Button "Comparer")
- `#llm-judge-results-table` (DataTable comparaison)

**Priorisation**:
- **U = 2** (curiosit√©, pas critique)
- **I = 4** (am√©liore s√©lection mod√®le)
- **E = 3** (5+ calls LLM parall√®les + UI)
- **RoI = (2√ó4) / max(1,3-1) = 4.0** (boost √† 6.0 car recherche)

**Bloquants**:
- ‚ö†Ô∏è g4f providers instables (certains models down)

**Modules r√©utilis√©s**:
- `src/agents/llm/runtime.py`

**√âtapes dev**:
1. Cr√©er layout `/llm_judge`:
   ```python
   def layout():
       return html.Div([
           dbc.Textarea(id="llm-judge-input", placeholder="Posez une question macro..."),
           dbc.Checklist(id="llm-judge-models", options=[
               {"label": "DeepSeek R1", "value": "deepseek-ai/DeepSeek-R1-0528"},
               {"label": "Qwen 2.5", "value": "qwen-2.5"},
               # ...
           ], value=["deepseek-ai/DeepSeek-R1-0528"]),
           dbc.Button("Comparer", id="llm-judge-run-btn"),
           html.Div(id="llm-judge-results")
       ])
   ```
2. Callback:
   ```python
   @callback(Output("llm-judge-results", "children"), Input("llm-judge-run-btn", "n_clicks"), State("llm-judge-input", "value"), State("llm-judge-models", "value"))
   def compare_models(n, question, models):
       results = []
       for model in models:
           start = time.time()
           response = LLMClient(model=model).generate([{"role": "user", "content": question}])
           latency = time.time() - start
           results.append({"model": model, "response": response, "latency_ms": int(latency * 1000)})
       return dbc.Table.from_dataframe(pd.DataFrame(results))
   ```
3. Tests: `tests/test_llm_judge.py`

---

### [16-20] Id√©es Additionnelles (r√©sum√©)

**[16] Earnings Impact Analysis**
- Analyser returns 3d avant/apr√®s earnings
- Output: `data/analytics/earnings_impact.json`
- **RoI = 5.3** (recherche, pas priorit√©)

**[17] Regime Switching Indicators**
- Hidden Markov Model (HMM) pour d√©tection r√©gimes
- Am√©liore pr√©cision vs heuristiques actuelles
- **RoI = 5.0** (complexit√© ML)

**[18] Risk Parity Portfolio Optimizer**
- Pond√©ration bas√©e variance √©gale (pas score)
- R√©duit volatilit√© portfolio
- **RoI = 5.0** (ML advanced)

**[19] WebSocket Live Updates**
- Push notifications UI (pas polling interval)
- R√©duit latency affichage
- **RoI = 4.0** (infrastructure)

**[20] Multi-User Auth**
- Login/logout, watchlists par user
- **RoI = 3.0** (hors scope investisseur unique)

---

## üìã Roadmap Recommand√©e

### Sprint 1 (Priorit√© Haute, RoI > 15)
1. ‚úÖ [01] Investor Overview
2. ‚úÖ [02] Backtest Agent Complet
3. ‚úÖ [03] Agents Health Panel

### Sprint 2 (Priorit√© Medium, RoI 10-15)
4. ‚úÖ [04] Macro Enrichissement
5. ‚úÖ [05] News ‚Üí Signal LLM
6. ‚úÖ [06] Deep Ticker Snapshot
7. ‚úÖ [07] ML Baseline Int√©gration
8. ‚úÖ [08] Evaluation Agent Full

### Sprint 3 (Priorit√© Low, RoI 5-10)
9. [09] Arbitre Multi-Agents LLM
10. [10] Portfolio Explainability
11. [11] Alerts Badge Dynamique
12. [12] Beginner Mode
13. [13] SearXNG News Ingestion
14. [14] Watchlist Coverage Quality
15. [15] LLM Judge Full

### Sprint 4+ (Recherche, RoI < 5)
16-20. Analytics avanc√©s, infrastructure long terme

---

**Fin du Backlog**
