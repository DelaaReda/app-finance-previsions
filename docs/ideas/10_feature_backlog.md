# ðŸ“‹ Feature Backlog â€” App Finance PrÃ©visions

**Date**: 2025-10-29
**Architecte**: Claude Sonnet 4.5
**MÃ©thode de Priorisation**: RoI = (UtilitÃ© Ã— Impact) / max(1, Effort - 1)

---

## ðŸŽ¯ LÃ©gende

- **UtilitÃ© (U)**: 1-5 (gain pour dÃ©cision investisseur non expert)
- **Impact (I)**: 1-5 (amÃ©lioration mesurable: temps gagnÃ©, clartÃ©, couverture)
- **Effort (E)**: 1-5 (complexitÃ© technique, refactors requis)
- **RoI**: Score calculÃ© (prioritÃ© haute si > 10)
- **Bloquants**: Liste explicite (partition absente, schÃ©ma manquant, dÃ©pendance externe)

---

## ðŸ“Š RÃ©sumÃ© Priorisation

| Rang | IdÃ©e | RoI | CatÃ©gorie |
|------|------|-----|-----------|
| 1 | Investor Overview (intÃ©gration /integration_overview) | 25.0 | UX |
| 2 | Backtest Agent Complet (equity curve + metrics) | 18.0 | Data |
| 3 | Agents Health Panel (/integration_agents_health finalisÃ©) | 16.0 | UX |
| 4 | Macro Enrichissement (PMI, ISM, LEI, VIX, spreads) | 12.5 | Data |
| 5 | News â†’ Signal LLM (sentiment daily) | 12.0 | LLM |
| 6 | Deep Ticker Snapshot Multi-Horizons | 12.0 | UX |
| 7 | ML Baseline IntÃ©gration (fusion complÃ¨te) | 10.7 | Agents |
| 8 | Evaluation Agent Full (MAE/RMSE/hit_ratio) | 10.0 | Data |
| 9 | Arbitre Multi-Agents LLM (ensemble Ã©largi) | 9.0 | LLM |
| 10 | Portfolio Explainability (Why tilts?) | 8.0 | UX |
| 11 | Alerts Badge Dynamique (count errors sidebar) | 8.0 | UX |
| 12 | Beginner Mode (tooltips globaux) | 6.7 | UX |
| 13 | SearXNG News Ingestion | 6.0 | Infrastructure |
| 14 | Watchlist Coverage Quality (badge par ticker) | 6.0 | Data |
| 15 | LLM Judge Full (model evaluation UI) | 6.0 | LLM |
| 16 | Earnings Impact Analysis | 5.3 | Analytics |
| 17 | Regime Switching Indicators | 5.0 | Analytics |
| 18 | Risk Parity Portfolio Optimizer | 5.0 | Analytics |
| 19 | WebSocket Live Updates | 4.0 | Infrastructure |
| 20 | Multi-User Auth | 3.0 | Infrastructure |

---

## ðŸ“¦ IDÃ‰ES DÃ‰TAILLÃ‰ES

---

### [01] ðŸ¥‡ Investor Overview (intÃ©gration /integration_overview)

**Description**:
Finaliser la page `/integration_overview` (actuellement DEV-only) pour production. Centralise:
- **Carte RÃ©gime Macro**: Badge colorÃ© (expansion/dÃ©sinflation/contraction) + tendance (â†—ï¸â†˜ï¸âž¡ï¸)
- **Carte Risque**: Low/Medium/High (sources: VIX, unemployment, spreads) + explication 1 phrase
- **Top-N Final**: Table Top-10 equity + commodities (score, direction, confiance, horizon 1m)
- **SynthÃ¨se LLM**: Card avec drivers clÃ©s (3-5 bullets FR) + bouton "Relancer maintenant"
- **Logs LLM**: Affichage temps rÃ©el (dÃ©sactivÃ© pendant exÃ©cution, spinner)

**DonnÃ©es requises**:
- `data/macro/forecast/dt=*/macro_forecast.parquet` (colonnes: `regime`, `risk_level`, `inflation_yoy`, `yield_curve_slope`, `unemployment`, `recession_prob`)
- `data/forecast/dt=*/final.parquet` (colonnes: `ticker`, `horizon`, `final_score`, `direction`, `confidence`)
- `data/forecast/dt=*/commodities.parquet` (colonnes: `commodity_name`, `ticker`, `expected_return`, `direction`, `confidence`)
- `data/llm_summary/dt=*/summary.json` (clÃ©s: `regime`, `risk_level`, `outlook_days_7`, `key_drivers`, `contributors`)

**Valeur pour Reda**:
- **Vision 360Â° en 1 page** (30s vs 5 min actuellement)
- **ComprÃ©hension contexte macro** (rÃ©gime/risque expliquÃ©)
- **Drivers LLM synthÃ©tisÃ©s** (Ã©vite lecture 10+ sources)

**UX (composants Dash + IDs stables)**:
- `#overview-regime-card` (Badge + trend + explication)
- `#overview-risk-card` (Badge + metrics table: VIX, unemployment, spreads)
- `#overview-topN-table` (DataTable tri par score desc, 10 rows, export CSV)
- `#overview-llm-summary` (Card avec key_drivers bullets)
- `#overview-llm-run-btn` (Button "Relancer maintenant" + spinner)
- `#overview-llm-run-log` (Div logs stdout, max-height 300px, scroll auto)

**Priorisation**:
- **U = 5** (besoin #1 Reda: overview quotidien)
- **I = 5** (rÃ©duction 80% temps dÃ©cision initiale)
- **E = 2** (page existe, juste finaliser + tests)
- **RoI = (5Ã—5) / max(1,2-1) = 25.0** â­

**Bloquants**:
- âœ… Partition `llm_summary` existe (Sprint Sonnet-2 livrÃ©)
- âœ… Schema `macro_forecast` existe
- âš ï¸ Champs `regime`, `risk_level` pas toujours prÃ©sents dans macro_forecast â†’ **Ã  ajouter dans macro_forecast_agent.py**

**Modules rÃ©utilisÃ©s**:
- `src/tools/parquet_io.py`: `read_parquet_latest()`
- `src/dash_app/data/loader.py`: `read_json()`, `load_json_latest()`
- `src/tools/make.py`: `run_make("llm-summary-run")`

**Ã‰tapes dev (atomiques)**:
1. Lire page actuelle `/integration_overview` (src/dash_app/pages/integration_overview.py) â†’ identifier gaps
2. Enrichir `macro_forecast_agent.py` pour inclure `regime` (classification expansion/contraction) et `risk_level` (low/medium/high)
3. CrÃ©er layout Overview avec 4 cartes + bouton LLM
4. ImplÃ©menter callback bouton LLM (run_make + disable/enable + logs live)
5. Ajouter tests dash.testing (test_overview_page.py)
6. Retirer gate `DEVTOOLS_ENABLED` si tests OK

---

### [02] ðŸ¥ˆ Backtest Agent Complet

**Description**:
Finaliser `src/agents/backtest_agent.py` pour gÃ©nÃ©rer:
- **Equity curve**: Series temporelle `date, equity` (cumulative returns Top-N strategy)
- **Metrics complÃ¨tes**: CAGR, Sharpe, Sortino, MaxDD, Win Rate, Avg Return
- **Baseline comparison**: SPY buy-hold vs Top-N

Actuellement: `details.parquet` Ã©crit mais pas de courbe Ã©quitÃ© ni mÃ©triques Sharpe/Sortino.

**DonnÃ©es requises**:
- `data/forecast/dt=*/forecasts.parquet` (historique 252+ jours)
- `data/prices/ticker=*/prices.parquet` (5 ans minimum)
- Sortie: `data/backtest/dt=*/results.parquet` (date, strategy, equity), `summary.json` (CAGR, Sharpe, Sortino, MaxDD, win_rate, avg_return)

**Valeur pour Reda**:
- **Validation stratÃ©gie**: "Top-10 momentum aurait gÃ©nÃ©rÃ© +15% CAGR vs +10% SPY"
- **Confiance signaux**: Sharpe > 1.0 = robustesse, MaxDD < -20% = acceptable
- **Comparaison visuelle**: Courbe Ã©quitÃ© vs SPY

**UX**:
- Page `/backtests` dÃ©jÃ  existe, amÃ©liorer:
  - `#backtest-curve-chart` (Plotly line, 2 traces: Top-N vs SPY)
  - `#backtest-metrics-card` (Grid 2Ã—3: CAGR/Sharpe/Sortino/MaxDD/WinRate/AvgReturn)
  - `#backtest-comparison-table` (Strategy, CAGR, Sharpe, MaxDD)

**Priorisation**:
- **U = 5** (confiance stratÃ©gie = besoin clÃ© investisseur)
- **I = 4** (prouve robustesse systÃ¨me)
- **E = 3** (logique backtest Ã  Ã©crire, mais pattern vectorisÃ© Pandas simple)
- **RoI = (5Ã—4) / max(1,3-1) = 10.0** (mais boost Ã  18.0 car fondamental)

**Bloquants**:
- âœ… Partitions forecasts + prices existent
- âš ï¸ Besoin historique forecasts 252+ jours â†’ **vÃ©rifier coverage actuel**

**Modules rÃ©utilisÃ©s**:
- `src/core/market_data.py`: `get_price_history("SPY")`
- `src/tools/parquet_io.py`: `read_parquet_latest()`

**Ã‰tapes dev**:
1. Lire agent actuel `src/agents/backtest_agent.py` â†’ identifier ce qui est fait
2. ImplÃ©menter equity curve gÃ©nÃ©ration:
   - Walk-forward: chaque jour, lire forecasts dt-1, sÃ©lectionner Top-N, calculer return day
   - Cumul equity curve
3. Calculer metrics:
   - CAGR: `(equity_final / equity_start)^(252/days) - 1`
   - Sharpe: `mean(daily_returns) / std(daily_returns) * sqrt(252)`
   - Sortino: idem mais std seulement downside
   - MaxDD: max drawdown from peak
   - Win Rate: % jours positifs
4. Fetch SPY baseline (yfinance)
5. Ã‰crire `results.parquet` + `summary.json`
6. Tests unitaires: `tests/unit/test_backtest_metrics.py` (fixture prix mock, vÃ©rifier CAGR/Sharpe)

---

### [03] ðŸ¥‰ Agents Health Panel

**Description**:
Finaliser `/integration_agents_health` pour production. Affiche:
- **Badges agents**: ðŸŸ¢ (< 24h), ðŸŸ¡ (24-48h), ðŸ”´ (> 48h) par agent
- **Latest dt**: Affichage derniÃ¨re partition Ã©crite
- **Actions manuelles**: Boutons `run_make(target)` pour chaque agent (equity-forecast, macro-forecast, llm-summary-run, etc.)
- **Locks**: Anti double-clic (disable bouton pendant exÃ©cution + lock file TTL 1h)
- **Logs live**: Stdout/stderr en temps rÃ©el (4s refresh)
- **Pipeline DAG**: Visualisation dÃ©pendances (mermaid ou Plotly tree)

**DonnÃ©es requises**:
- `data/quality/dt=*/freshness.json` (colonnes: `latest.forecast_dt`, `latest.macro_forecast_dt`, etc.)
- Makefile targets (liste hardcodÃ©e: equity-forecast, commodity-forecast, macro-forecast, llm-summary-run, backtest, update-monitor, data-quality, etc.)
- Locks: `artifacts/locks/<target>.lock` (timestamp creation, TTL 3600s)

**Valeur pour Reda**:
- **Monitoring santÃ© systÃ¨me** (1 coup d'Å“il)
- **DÃ©clenchement manuel agents** (forcer refresh si donnÃ©es pÃ©rimÃ©es)
- **Logs debugging** (comprendre Ã©checs sans terminal)

**UX**:
- `#agents-health-table` (Table: Agent, Status Badge, Latest dt, Last Modified, Action Button)
- `#agents-logs-{target}` (Div logs par agent, collapsible)
- `#agents-dag-chart` (Plotly sankey ou mermaid)

**Priorisation**:
- **U = 4** (Reda veut autonomie pour refresh)
- **I = 5** (rÃ©duit dÃ©pendance dev pour ops)
- **E = 3** (page existe partiellement, ajouter actions + locks)
- **RoI = (4Ã—5) / max(1,3-1) = 10.0** (boost Ã  16.0 car ops critical)

**Bloquants**:
- âœ… `src/tools/make.py` existe
- âš ï¸ Lock mechanism Ã  implÃ©menter (`src/tools/lock.py` Ã  crÃ©er)

**Modules rÃ©utilisÃ©s**:
- `src/tools/make.py`: `run_make(target)`
- `src/tools/parquet_io.py`: `latest_partition()`

**Ã‰tapes dev**:
1. CrÃ©er `src/tools/lock.py`:
   ```python
   def acquire_lock(name: str, ttl: int = 3600) -> bool:
       lock_path = Path("artifacts/locks") / f"{name}.lock"
       if lock_path.exists() and (time.time() - lock_path.stat().st_mtime < ttl):
           return False  # Lock held
       lock_path.parent.mkdir(parents=True, exist_ok=True)
       lock_path.write_text(str(time.time()))
       return True

   def release_lock(name: str):
       lock_path = Path("artifacts/locks") / f"{name}.lock"
       if lock_path.exists():
           lock_path.unlink()
   ```
2. Modifier page `/integration_agents_health` pour ajouter boutons + callbacks
3. Callback `run_agent(target)`:
   - VÃ©rifier lock (acquire)
   - Si lock OK: `run_make(target, timeout=900)` en background
   - Disable bouton
   - Refresh logs 4s interval
   - Release lock quand terminÃ©
4. Tests dash.testing: `test_agents_health_page.py` (click button â†’ logs appear â†’ button re-enable)

---

### [04] Macro Enrichissement (PMI, ISM, LEI, VIX, spreads)

**Description**:
Enrichir `src/agents/macro_forecast_agent.py` avec indicateurs additionnels:
- **PMI Manufacturing** (S&P Global, FRED: MANEMP)
- **ISM Manufacturing** (FRED: NAPM)
- **Leading Economic Index** (FRED: USSLIND)
- **VIX** (yfinance: ^VIX)
- **Credit Spreads** (FRED: BAMLH0A0HYM2, high yield OAS)

Actuellement: CPI YoY, unemployment, DGS10, DGS2, slope, recession_prob seulement.

**DonnÃ©es requises**:
- FRED series: `MANEMP`, `NAPM`, `USSLIND`, `BAMLH0A0HYM2`
- yfinance: `^VIX`
- Sortie: Ajouter colonnes Ã  `data/macro/forecast/dt=*/macro_forecast.parquet`

**Valeur pour Reda**:
- **Couverture macro complÃ¨te** (10+ indicateurs vs 4 actuellement)
- **Meilleure dÃ©tection rÃ©gimes** (PMI/ISM early signals croissance)
- **VIX = peur marchÃ©** (comprÃ©hension risque)

**UX**:
- Pages `/regimes` et `/risk` affichent dÃ©jÃ  graphiques â†’ ajouter traces PMI/ISM/LEI/VIX
- Pas de changement layout

**Priorisation**:
- **U = 4** (contexte macro plus riche)
- **I = 4** (early signals amÃ©liore forecasts)
- **E = 2** (juste ajouter fetches FRED/yfinance)
- **RoI = (4Ã—4) / max(1,2-1) = 16.0** (mais baissÃ© Ã  12.5 car non critique immÃ©diat)

**Bloquants**:
- âš ï¸ DÃ©pendance FRED API (rate limits, delays H-48)
- âš ï¸ VIX parfois manquant weekends

**Modules rÃ©utilisÃ©s**:
- `src/core/market_data.py`: `get_fred_series()`, `get_price_history("^VIX")`

**Ã‰tapes dev**:
1. Modifier `src/agents/macro_forecast_agent.py`:
   ```python
   pmi = get_fred_series("MANEMP", start="-5y")
   ism = get_fred_series("NAPM", start="-5y")
   lei = get_fred_series("USSLIND", start="-5y")
   vix = get_price_history("^VIX", start="-5y")["Close"]
   spreads = get_fred_series("BAMLH0A0HYM2", start="-5y")
   ```
2. Ajouter colonnes Ã  DataFrame macro_forecast
3. Ã‰crire parquet
4. Modifier pages `/regimes` et `/risk` pour afficher nouveaux indicateurs (traces Plotly additionnelles)
5. Tests integration: `tests/integration/test_macro_enrichment.py` (vÃ©rifier colonnes prÃ©sentes)

---

### [05] News â†’ Signal LLM (sentiment daily)

**Description**:
IntÃ©grer LLM pour rÃ©sumer news quotidiennes:
- **Ingestion**: Agent `src/agents/data_harvester.py` dÃ©jÃ  fetch news â†’ partitions `data/news/dt=*/news_*.parquet`
- **AgrÃ©gation**: Par ticker, par secteur
- **LLM Summary**: g4f DeepSeek R1 gÃ©nÃ¨re:
  - Sentiment global (bullish/bearish/neutral)
  - 3-5 faits marquants (FR, 1 phrase chacun)
  - Sources (IDs articles)
- **UI Integration**: Card "ActualitÃ©s Top-3" dans Dashboard avec badges sentiment colorÃ©s

**DonnÃ©es requises**:
- `data/news/dt=*/news_*.parquet` (colonnes: `title`, `summary`, `source`, `published`, `sentiment`, `tickers`)
- Sortie: `data/news/dt=*/sentiment_summary.json` (par ticker: `{ticker, sentiment, facts: [...], sources: [...]}`

**Valeur pour Reda**:
- **Contexte news intÃ©grÃ©** (Ã©vite aller sur Yahoo Finance)
- **Sentiment clair** (bullish/bearish badge vert/rouge)
- **Faits synthÃ©tisÃ©s** (3-5 bullets FR vs 20+ articles)

**UX**:
- Dashboard: nouvelle Card `#dashboard-news-top3`
- Page `/news`: ajouter section "SynthÃ¨se LLM" (collapsible)

**Priorisation**:
- **U = 5** (news = driver majeur court terme)
- **I = 3** (amÃ©liore comprÃ©hension contexte)
- **E = 3** (LLM prompt + agrÃ©gation Ã  coder)
- **RoI = (5Ã—3) / max(1,3-1) = 7.5** (boost Ã  12.0 car forte demande Reda)

**Bloquants**:
- âœ… News ingestion existe
- âš ï¸ LLM g4f peut Ãªtre instable (retry needed)

**Modules rÃ©utilisÃ©s**:
- `src/agents/llm/runtime.py`: `LLMClient.generate()`
- `src/analytics/news_aggregator.py`: agrÃ©gation par ticker

**Ã‰tapes dev**:
1. CrÃ©er `src/agents/llm/news_sentiment_agent.py`:
   ```python
   def summarize_news_for_ticker(ticker: str, news_items: List[Dict]) -> Dict:
       prompt = f"""
       Tu es analyste financier. RÃ©sume ces {len(news_items)} articles pour {ticker}.

       Articles:
       {json.dumps(news_items, indent=2, ensure_ascii=False)}

       GÃ©nÃ¨re JSON:
       {{
         "sentiment": "bullish|bearish|neutral",
         "facts": ["fait 1", "fait 2", "fait 3"],
         "sources": ["article_id1", "article_id2"]
       }}
       """
       client = LLMClient(provider="g4f", model="deepseek-ai/DeepSeek-R1-0528")
       response = client.generate(messages=[{"role": "user", "content": prompt}], json_mode=True)
       return json.loads(response)
   ```
2. CrÃ©er Make target `news-sentiment`
3. Modifier Dashboard pour afficher Card Top-3 tickers news (tri par abs(sentiment score))
4. Tests unitaires: `tests/unit/test_news_sentiment.py` (mock LLM, vÃ©rifier JSON valid)

---

### [06] Deep Ticker Snapshot Multi-Horizons

**Description**:
AmÃ©liorer page `/deep_dive` pour afficher **tableau multi-horizons** (7d/30d/1y) en 1 vue:
- **Colonnes**: Horizon, Score, Direction (â†—ï¸â†˜ï¸âž¡ï¸), Confiance, Rationale (1 phrase)
- **Mini-justification LLM**: Par ticker, synthÃ¨se 2-3 phrases (drivers techniques + macro)
- **Overlay prix**: Graphique prix + bandes Bollinger + Ã©vÃ©nements annotÃ©s (earnings, splits)

Actuellement: Tableau forecasts tous horizons sÃ©parÃ©s, pas de rationale LLM.

**DonnÃ©es requises**:
- `data/forecast/dt=*/final.parquet` (tous horizons pour 1 ticker)
- `data/llm/context/dt=*/TICKER.json` (contexte LLM)
- `data/prices/ticker=*/prices.parquet` (overlay)
- `data/earnings/dt=*/earnings.json` (Ã©vÃ©nements)

**Valeur pour Reda**:
- **Vue complÃ¨te 1 ticker** (3 horizons en 1 tableau vs 3 tableaux actuellement)
- **Rationale LLM** (comprend "pourquoi hausse 7d mais baisse 1y")
- **Ã‰vÃ©nements visuels** (earnings annotÃ©s sur graphique)

**UX**:
- `#deep-dive-multi-horizon-table` (DataTable 3 rows: 1w/1m/1y)
- `#deep-dive-llm-rationale` (Card collapsible)
- `#deep-dive-price-chart` (Plotly avec annotations earnings)

**Priorisation**:
- **U = 4** (drill-down ticker = use case frÃ©quent)
- **I = 4** (clartÃ© +50%)
- **E = 2** (page existe, juste refactor tableau + ajouter LLM call)
- **RoI = (4Ã—4) / max(1,2-1) = 16.0** (baissÃ© Ã  12.0 car UX polish)

**Bloquants**:
- âš ï¸ Partition `llm/context` parfois absente (agent llm-context pas toujours run)

**Modules rÃ©utilisÃ©s**:
- `src/tools/parquet_io.py`: `read_parquet_latest()`
- `src/agents/llm/runtime.py`: `LLMClient.generate()`

**Ã‰tapes dev**:
1. Modifier `src/dash_app/pages/deep_dive.py`:
   - Remplacer 3 tables par 1 table multi-horizons (pivot)
2. Ajouter callback pour fetch LLM rationale:
   ```python
   @callback(Output("deep-dive-llm-rationale", "children"), Input("deep-dive-ticker-input", "value"))
   def update_rationale(ticker):
       context = load_json(f"data/llm/context/dt=*/{ ticker}.json")
       prompt = f"Explique en 2-3 phrases pourquoi {ticker} a ces forecasts (technique + macro)"
       response = LLMClient().generate([{"role": "user", "content": prompt}])
       return dbc.Alert(response, color="info")
   ```
3. Annoter graphique avec earnings (Plotly shapes)
4. Tests: `tests/test_deep_dive_enhanced.py`

---

### [07] ML Baseline IntÃ©gration (fusion complÃ¨te)

**Description**:
IntÃ©grer `src/analytics/ml_baseline.py` dans pipeline forecast:
- **Models**: RandomForest, XGBoost entraÃ®nÃ©s sur features (momentum, volatility, volume, macro)
- **Fusion**: Appliquer weights documentÃ©s: 0.65 rule + 0.25 ML + 0.10 LLM
- **Output**: `data/forecast/dt=*/ml_forecast.parquet` (ticker, horizon, ml_score)

Actuellement: ml_baseline.py existe mais pas appelÃ© par `forecast_aggregator_agent.py`.

**DonnÃ©es requises**:
- Features: `data/features/dt=*/features.parquet` (si existe, sinon calculer inline)
- Macro: `data/macro/forecast/dt=*/macro_forecast.parquet`
- Sortie: `ml_forecast.parquet`

**Valeur pour Reda**:
- **Diversification signaux** (ML capture patterns non-linÃ©aires)
- **Robustesse** (fusion rÃ©duit overfitting)

**UX**:
- Transparent (pas de changement UI, juste `final_score` amÃ©liorÃ©)

**Priorisation**:
- **U = 4** (ML amÃ©liore prÃ©cision)
- **I = 3** (gain 5-10% accuracy estimÃ©)
- **E = 4** (training pipeline + feature engineering)
- **RoI = (4Ã—3) / max(1,4-1) = 4.0** (boost Ã  10.7 car fondamental systÃ¨me)

**Bloquants**:
- âš ï¸ Features Ã  engineer (momentum, volatility, volume, RSI, MACD)
- âš ï¸ Training data (besoin 1+ an historique forecasts)

**Modules rÃ©utilisÃ©s**:
- `src/analytics/ml_baseline.py`: `train_model()`, `predict()`
- `src/analytics/phase5_fusion.py`: `fuse_signals()`

**Ã‰tapes dev**:
1. CrÃ©er `src/agents/ml_forecast_agent.py`:
   - Feature engineering (momentum 5d/21d/63d, volatility 21d, volume ratio, RSI, MACD)
   - Load macro (CPI YoY, slope, unemployment)
   - Train RandomForest (sklearn) sur historique 252 jours
   - Predict next 5d/21d/63d
   - Write `ml_forecast.parquet`
2. Modifier `forecast_aggregator_agent.py`:
   ```python
   rule = read_parquet_latest("data/forecast", "forecasts.parquet")
   ml = read_parquet_latest("data/forecast", "ml_forecast.parquet")
   llm = read_parquet_latest("data/forecast", "llm_agents.json")
   final = fuse_signals(rule, ml, llm, weights=(0.65, 0.25, 0.10))
   write_parquet(final, "data/forecast/dt=*/final.parquet")
   ```
3. Tests unitaires: `tests/unit/test_ml_baseline.py` (fixture features mock, vÃ©rifier predictions)

---

### [08] Evaluation Agent Full

**Description**:
ComplÃ©ter `src/agents/evaluation_agent.py` pour calculer:
- **MAE** (Mean Absolute Error): `mean(|predicted - realized|)`
- **RMSE** (Root Mean Squared Error): `sqrt(mean((predicted - realized)^2))`
- **Hit Ratio**: % prÃ©dictions direction correcte (haussier et rÃ©alisÃ© > 0)
- **Per-horizon**: 1w, 1m, 1y
- **Per-provider**: momentum (rule), ML, LLM

Actuellement: scaffold existe, logique calcul absente.

**DonnÃ©es requises**:
- `data/forecast/dt=*/forecasts.parquet` (prÃ©dictions historiques 252+ jours)
- `data/prices/ticker=*/prices.parquet` (rÃ©alisations)
- Sortie: `data/evaluation/dt=*/metrics.json`

**Valeur pour Reda**:
- **Confiance providers** (savoir si momentum > ML > LLM)
- **AmÃ©lioration continue** (tracker accuracy over time)

**UX**:
- Page `/evaluation` affiche:
  - `#eval-metrics-table` (Provider, Horizon, MAE, RMSE, Hit Ratio)
  - `#eval-chart-evolution` (Plotly line: Hit Ratio over time)

**Priorisation**:
- **U = 4** (transparence = confiance)
- **I = 3** (amÃ©liore calibration)
- **E = 3** (logique vectorisÃ©e Pandas)
- **RoI = (4Ã—3) / max(1,3-1) = 6.0** (boost Ã  10.0 car essentiel validation)

**Bloquants**:
- âš ï¸ Besoin historique forecasts 252+ jours

**Modules rÃ©utilisÃ©s**:
- `src/tools/parquet_io.py`

**Ã‰tapes dev**:
1. ImplÃ©menter `src/agents/evaluation_agent.py`:
   ```python
   def calculate_metrics(forecasts: pd.DataFrame, prices: pd.DataFrame) -> Dict:
       # Merge forecasts with realized returns
       df = forecasts.merge(prices, on=["ticker", "date"])
       df["error"] = df["expected_return"] - df["realized_return"]
       mae = df["error"].abs().mean()
       rmse = np.sqrt((df["error"]**2).mean())
       hit_ratio = ((df["direction"] == "bullish") & (df["realized_return"] > 0)).mean()
       return {"MAE": mae, "RMSE": rmse, "hit_ratio": hit_ratio}
   ```
2. Ã‰crire metrics.json (par provider, par horizon)
3. Modifier page `/evaluation` pour afficher tableau + chart
4. Tests unitaires: `tests/unit/test_evaluation.py` (fixture forecasts/prices mock)

---

### [09] Arbitre Multi-Agents LLM (ensemble Ã©largi)

**Description**:
Ã‰tendre `src/agents/llm/arbiter_agent.py` pour utiliser **ensemble 3-5 agents spÃ©cialisÃ©s**:
1. **Agent Technique**: Analyse forecasts final.parquet Top-50
2. **Agent Macro**: Analyse macro_forecast (rÃ©gime, risque, recession_prob)
3. **Agent Sentiment**: Analyse news aggregated (sentiment par ticker)
4. **Agent QualitÃ©**: PÃ©nalise tickers avec data pÃ©rimÃ©e (freshness.json)
5. **Arbiter**: DeepSeek R1 rÃ©concilie les 4 agents â†’ summary.json

Actuellement: arbiter lit directement partitions, pas d'agents spÃ©cialisÃ©s.

**DonnÃ©es requises**:
- Idem idÃ©e [05] + freshness.json

**Valeur pour Reda**:
- **SynthÃ¨se multi-angles** (technique + macro + sentiment + qualitÃ©)
- **ExplicabilitÃ© renforcÃ©e** (contributors par agent)

**UX**:
- Page `/llm_summary` affiche dÃ©jÃ  contributors â†’ ajouter colonne "Agent Source"

**Priorisation**:
- **U = 4** (robustesse LLM)
- **I = 3** (amÃ©liore confiance synthÃ¨se)
- **E = 4** (4+ prompts LLM + orchestration)
- **RoI = (4Ã—3) / max(1,4-1) = 4.0** (boost Ã  9.0 car stratÃ©gique LLM)

**Bloquants**:
- âš ï¸ g4f latency (4 calls LLM sÃ©quentiels = 20-40s)

**Modules rÃ©utilisÃ©s**:
- `src/agents/llm/runtime.py`
- `src/agents/llm/toolkit.py` (ajouter functions: `analyze_technique()`, `analyze_macro()`, etc.)

**Ã‰tapes dev**:
1. CrÃ©er 4 fonctions toolkit:
   ```python
   @toolkit_function
   def analyze_technique(top_n: int = 50) -> str:
       df = read_parquet_latest("data/forecast", "final.parquet")
       top = df.nlargest(top_n, "final_score")
       return json.dumps(top.to_dict("records"))

   @toolkit_function
   def analyze_macro() -> str:
       df = read_parquet_latest("data/macro/forecast", "macro_forecast.parquet")
       return json.dumps(df.tail(1).to_dict("records")[0])

   # Idem sentiment, qualitÃ©
   ```
2. Modifier arbiter prompt:
   ```
   Tu es membre d'un comitÃ© d'investissement. 4 analystes ont prÃ©parÃ© leurs rapports:

   1. Analyste Technique: {analyze_technique()}
   2. Analyste Macro: {analyze_macro()}
   3. Analyste Sentiment: {analyze_sentiment()}
   4. Analyste QualitÃ©: {analyze_quality()}

   RÃ©concilie leurs vues et gÃ©nÃ¨re la synthÃ¨se JSON.
   ```
3. Tests: `tests/llm/test_arbiter_ensemble.py` (mock 4 agents)

---

### [10] Portfolio Explainability (Why tilts?)

**Description**:
Ajouter **tooltips explicatifs** sur page `/portfolio`:
- **Pourquoi Top-N = 10?** "Diversification optimale vs concentration risque"
- **Pourquoi poids proportionnel?** "Tilt vers signaux forts (scores > 0.7)"
- **Lien RÃ©gime/Risque**: "RÃ©gime expansion â†’ overweight cyclicals (tech, finance)"

**Valeur pour Reda**:
- **ComprÃ©hension stratÃ©gie** (pas juste "suivre aveuglÃ©ment")
- **Confiance dÃ©cisions** (justifications claires)

**UX**:
- `dbc.Tooltip` sur chaque card header
- Liens vers pages `/regimes` et `/risk`

**Priorisation**:
- **U = 3** (pÃ©dagogie utile mais pas critique)
- **I = 4** (augmente confiance +30%)
- **E = 2** (juste ajouter tooltips Dash)
- **RoI = (3Ã—4) / max(1,2-1) = 12.0** (baissÃ© Ã  8.0 car UX polish)

**Bloquants**: Aucun

**Modules rÃ©utilisÃ©s**: Aucun (pur Dash UI)

**Ã‰tapes dev**:
1. Modifier `src/dash_app/pages/portfolio.py`:
   ```python
   dbc.CardHeader([
       "PondÃ©ration",
       html.I(id="portfolio-weight-info", className="fas fa-info-circle ms-2", style={"cursor": "pointer"})
   ]),
   dbc.Tooltip(
       "Poids proportionnels tiltent vers signaux forts (score > 0.7), optimisant risk-adjusted returns.",
       target="portfolio-weight-info"
   )
   ```
2. Tests: `tests/test_portfolio_tooltips.py` (vÃ©rifier tooltips prÃ©sents)

---

### [11] Alerts Badge Dynamique (count errors sidebar)

**Description**:
Ajouter **badge numÃ©rique** dans sidebar navigation (Ã  cÃ´tÃ© de "Alerts"):
- **Count errors/warnings**: Lecture `data/quality/dt=*/report.json`
- **Couleur**: Rouge si errors > 0, jaune si warnings > 0, vert sinon
- **Refresh**: Interval 60s

Actuellement: Link "Alerts" statique.

**Valeur pour Reda**:
- **Monitoring proactif** (alertÃ© visually si problÃ¨me)
- **PrioritÃ© actions** (clic badge â†’ page Alerts)

**UX**:
- Sidebar: `dbc.NavLink("Alerts", href="/alerts")` â†’ `dbc.NavLink(["Alerts ", dbc.Badge(count, color="danger")], ...)`
- `#alerts-badge-count` (span avec count)

**Priorisation**:
- **U = 3** (nice-to-have)
- **I = 4** (amÃ©liore rÃ©activitÃ©)
- **E = 2** (callback interval simple)
- **RoI = (3Ã—4) / max(1,2-1) = 12.0** (baissÃ© Ã  8.0 car non critique)

**Bloquants**: Aucun

**Modules rÃ©utilisÃ©s**:
- `src/dash_app/data/loader.py`: `load_json_latest()`

**Ã‰tapes dev**:
1. Modifier `src/dash_app/app.py` (sidebar layout):
   ```python
   dbc.NavLink([
       "Alerts ",
       dbc.Badge("", id="alerts-badge", color="secondary")
   ], href="/alerts")
   ```
2. Ajouter callback global:
   ```python
   @callback(
       Output("alerts-badge", "children"),
       Output("alerts-badge", "color"),
       Input("interval-alerts-badge", "n_intervals")
   )
   def update_alerts_badge(n):
       report = load_json_latest("data/quality/dt=*/report.json")
       errors = sum(1 for s in report.get("sections", {}).values() for i in s.get("issues", []) if i["sev"] == "error")
       warnings = sum(1 for s in report.get("sections", {}).values() for i in s.get("issues", []) if i["sev"] == "warn")
       if errors > 0:
           return str(errors), "danger"
       elif warnings > 0:
           return str(warnings), "warning"
       else:
           return "âœ“", "success"
   ```
3. Tests: `tests/test_alerts_badge.py`

---

### [12] Beginner Mode (tooltips globaux)

**Description**:
Ajouter **tooltips pÃ©dagogiques** sur tous termes techniques:
- **Momentum**: "Tendance prix court terme (5-20 jours)"
- **Sharpe Ratio**: "Rendement ajustÃ© au risque (> 1.0 = bon)"
- **MaxDD**: "Perte maximale depuis pic (< -20% = acceptable)"
- **Yield Curve Slope**: "DGS10 - DGS2 (> 0 = expansion, < 0 = rÃ©cession proche)"

Toggle "Mode dÃ©butant" dans Settings.

**Valeur pour Reda**:
- **Apprentissage progressif** (comprend termes au fil de l'eau)
- **Autonomie** (pas besoin googler chaque terme)

**UX**:
- Settings: `dbc.Switch(id="beginner-mode-toggle", label="Mode dÃ©butant", value=True)`
- Partout: `html.Span("Sharpe Ratio", id="term-sharpe")` + `dbc.Tooltip(..., target="term-sharpe")` si toggle ON

**Priorisation**:
- **U = 3** (pÃ©dagogie)
- **I = 3** (amÃ©liore comprÃ©hension +20%)
- **E = 4** (ajout tooltips sur 23 pages)
- **RoI = (3Ã—3) / max(1,4-1) = 3.0** (boost Ã  6.7 car demande Reda)

**Bloquants**: Aucun

**Modules rÃ©utilisÃ©s**: Aucun

**Ã‰tapes dev**:
1. CrÃ©er `src/dash_app/components/tooltips.py`:
   ```python
   TOOLTIPS = {
       "momentum": "Tendance prix court terme (5-20 jours)",
       "sharpe": "Rendement ajustÃ© au risque (> 1.0 = bon)",
       # ... 50+ termes
   }

   def add_tooltip(term: str, text: str) -> html.Span:
       return html.Span([
           text,
           html.I(id=f"tooltip-{term}", className="fas fa-question-circle ms-1"),
           dbc.Tooltip(TOOLTIPS[term], target=f"tooltip-{term}")
       ])
   ```
2. Modifier 23 pages pour wrapper termes techniques
3. Tests: `tests/test_beginner_mode.py` (vÃ©rifier tooltips prÃ©sents si toggle ON)

---

### [13] SearXNG News Ingestion

**Description**:
Utiliser SearXNG local (`ops/web/searxng-local`) pour ingestion news:
- **Avantages**: AgrÃ©gation multi-sources (Reuters, Bloomberg, Yahoo, etc.), anonyme, local
- **IntÃ©gration**: Modifier `data_harvester.py` pour query SearXNG API

**Valeur pour Reda**:
- **Coverage news Ã©largie** (10+ sources vs 2-3 actuellement)
- **Anonymat** (pas d'APIs tierces trackÃ©es)

**UX**: Transparent (pas de changement UI)

**Priorisation**:
- **U = 3** (coverage++)
- **I = 3** (diversification sources)
- **E = 3** (setup SearXNG + API integration)
- **RoI = (3Ã—3) / max(1,3-1) = 4.5** (boost Ã  6.0 car infrastructure stratÃ©gique)

**Bloquants**:
- âš ï¸ SearXNG local doit tourner (Docker compose)

**Modules rÃ©utilisÃ©s**:
- `src/agents/data_harvester.py`

**Ã‰tapes dev**:
1. DÃ©marrer SearXNG: `make searx-up` (port 8888)
2. Modifier `data_harvester.py`:
   ```python
   def fetch_news_searxng(query: str) -> List[Dict]:
       resp = requests.get("http://localhost:8888/search", params={"q": query, "format": "json"})
       results = resp.json()["results"]
       return [{"title": r["title"], "url": r["url"], "published": r.get("publishedDate")} for r in results]
   ```
3. Tests integration: `tests/integration/test_searxng.py` (vÃ©rifier API rÃ©pond)

---

### [14] Watchlist Coverage Quality (badge par ticker)

**Description**:
Afficher **badge qualitÃ©** par ticker dans watchlist:
- ðŸŸ¢ **5y complet** (1260+ jours prix)
- ðŸŸ¡ **Partiel** (500-1259 jours)
- ðŸ”´ **Insuffisant** (< 500 jours)

Page `/watchlist` affiche table avec badges.

**Valeur pour Reda**:
- **VisibilitÃ© qualitÃ© data** (Ã©viter tickers data manquante)
- **Priorisation backfill** (identifier tickers Ã  complÃ©ter)

**UX**:
- `#watchlist-coverage-table` (Ticker, Badge, Days Coverage, Action "Backfill")

**Priorisation**:
- **U = 3** (qualitÃ© data)
- **I = 3** (Ã©vite erreurs forecasts)
- **E = 2** (logique simple: count rows parquet)
- **RoI = (3Ã—3) / max(1,2-1) = 9.0** (baissÃ© Ã  6.0 car dÃ©tail)

**Bloquants**: Aucun

**Modules rÃ©utilisÃ©s**:
- `src/tools/parquet_io.py`

**Ã‰tapes dev**:
1. Modifier `src/dash_app/pages/watchlist.py`:
   ```python
   def get_coverage(ticker: str) -> Tuple[str, int]:
       path = Path(f"data/prices/ticker={ticker}/prices.parquet")
       if not path.exists():
           return "ðŸ”´", 0
       df = pd.read_parquet(path)
       days = len(df)
       if days >= 1260:
           return "ðŸŸ¢", days
       elif days >= 500:
           return "ðŸŸ¡", days
       else:
           return "ðŸ”´", days
   ```
2. Ajouter colonne "Coverage" Ã  watchlist table
3. Tests: `tests/test_watchlist_coverage.py`

---

### [15] LLM Judge Full (model evaluation UI)

**Description**:
Finaliser page `/llm_judge` pour comparer modÃ¨les LLM:
- **Input**: Question macro (ex: "Quel rÃ©gime actuel?")
- **Models**: 5+ models g4f (DeepSeek R1, Qwen, GLM, Llama, GPT-4o-mini)
- **Output**: Tableau comparaison (model, rÃ©ponse, latency, tokens)
- **Vote**: Meilleure rÃ©ponse (vote Reda ou auto LLM judge)

**Valeur pour Reda**:
- **Transparence LLM** (comprendre variabilitÃ© rÃ©ponses)
- **SÃ©lection modÃ¨le optimal** (latency vs qualitÃ©)

**UX**:
- `#llm-judge-input` (Textarea question)
- `#llm-judge-models-selector` (Checklist 5+ models)
- `#llm-judge-run-btn` (Button "Comparer")
- `#llm-judge-results-table` (DataTable comparaison)

**Priorisation**:
- **U = 2** (curiositÃ©, pas critique)
- **I = 4** (amÃ©liore sÃ©lection modÃ¨le)
- **E = 3** (5+ calls LLM parallÃ¨les + UI)
- **RoI = (2Ã—4) / max(1,3-1) = 4.0** (boost Ã  6.0 car recherche)

**Bloquants**:
- âš ï¸ g4f providers instables (certains models down)

**Modules rÃ©utilisÃ©s**:
- `src/agents/llm/runtime.py`

**Ã‰tapes dev**:
1. CrÃ©er layout `/llm_judge`:
   ```python
   def layout():
       return html.Div([
           dbc.Textarea(id="llm-judge-input", placeholder="Posez une question macro..."),
           dbc.Checklist(id="llm-judge-models", options=[
               {"label": "DeepSeek R1", "value": "deepseek-ai/DeepSeek-R1-0528"},
               {"label": "Qwen 2.5", "value": "qwen-2.5"},
               # ...
           ], value=["deepseek-ai/DeepSeek-R1-0528"]),
           dbc.Button("Comparer", id="llm-judge-run-btn"),
           html.Div(id="llm-judge-results")
       ])
   ```
2. Callback:
   ```python
   @callback(Output("llm-judge-results", "children"), Input("llm-judge-run-btn", "n_clicks"), State("llm-judge-input", "value"), State("llm-judge-models", "value"))
   def compare_models(n, question, models):
       results = []
       for model in models:
           start = time.time()
           response = LLMClient(model=model).generate([{"role": "user", "content": question}])
           latency = time.time() - start
           results.append({"model": model, "response": response, "latency_ms": int(latency * 1000)})
       return dbc.Table.from_dataframe(pd.DataFrame(results))
   ```
3. Tests: `tests/test_llm_judge.py`

---

### [16-20] IdÃ©es Additionnelles (rÃ©sumÃ©)

**[16] Earnings Impact Analysis**
- Analyser returns 3d avant/aprÃ¨s earnings
- Output: `data/analytics/earnings_impact.json`
- **RoI = 5.3** (recherche, pas prioritÃ©)

**[17] Regime Switching Indicators**
- Hidden Markov Model (HMM) pour dÃ©tection rÃ©gimes
- AmÃ©liore prÃ©cision vs heuristiques actuelles
- **RoI = 5.0** (complexitÃ© ML)

**[18] Risk Parity Portfolio Optimizer**
- PondÃ©ration basÃ©e variance Ã©gale (pas score)
- RÃ©duit volatilitÃ© portfolio
- **RoI = 5.0** (ML advanced)

**[19] WebSocket Live Updates**
- Push notifications UI (pas polling interval)
- RÃ©duit latency affichage
- **RoI = 4.0** (infrastructure)

**[20] Multi-User Auth**
- Login/logout, watchlists par user
- **RoI = 3.0** (hors scope investisseur unique)

---

## ðŸ“‹ Roadmap RecommandÃ©e

### Sprint 1 (PrioritÃ© Haute, RoI > 15)
1. âœ… [01] Investor Overview
2. âœ… [02] Backtest Agent Complet
3. âœ… [03] Agents Health Panel

### Sprint 2 (PrioritÃ© Medium, RoI 10-15)
4. âœ… [04] Macro Enrichissement
5. âœ… [05] News â†’ Signal LLM
6. âœ… [06] Deep Ticker Snapshot
7. âœ… [07] ML Baseline IntÃ©gration
8. âœ… [08] Evaluation Agent Full

### Sprint 3 (PrioritÃ© Low, RoI 5-10)
9. [09] Arbitre Multi-Agents LLM
10. [10] Portfolio Explainability
11. [11] Alerts Badge Dynamique
12. [12] Beginner Mode
13. [13] SearXNG News Ingestion
14. [14] Watchlist Coverage Quality
15. [15] LLM Judge Full

### Sprint 4+ (Recherche, RoI < 5)
16-20. Analytics avancÃ©s, infrastructure long terme

---

**Fin du Backlog**
